{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4de9652-f92c-4d19-a3c8-000d83301163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/hyunglokkim/Insync/hkim@geol.sc.edu/Google_Drive /Users/hyunglokkim/cpuserver_data\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import platform\n",
    "import importlib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "if platform.system() == 'Darwin':  # macOS\n",
    "    base_FP = '/Users/hyunglokkim/Insync/hkim@geol.sc.edu/Google_Drive'\n",
    "    cpuserver_data_FP = '/Users/hyunglokkim/cpuserver_data'\n",
    "elif platform.system() == 'Linux':\n",
    "    base_FP = '/data'\n",
    "    cpuserver_data_FP = '/data'\n",
    "else:\n",
    "    base_FP = '/data'\n",
    "    cpuserver_data_FP = '/data'\n",
    "sys.path.append(base_FP + '/python_modules')\n",
    "print(base_FP, cpuserver_data_FP)\n",
    "\n",
    "#hydroAI libs\n",
    "import HydroAI.ASCAT_TUW as hASCAT_TUW\n",
    "import HydroAI.Plot as hPlot\n",
    "import HydroAI.Data as hData\n",
    "import HydroAI.Grid as hGrid\n",
    "importlib.reload(hASCAT_TUW)\n",
    "importlib.reload(hPlot)\n",
    "importlib.reload(hData)\n",
    "importlib.reload(hGrid)\n",
    "\n",
    "# Ignore runtime warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Define your directory where to save nc files\n",
    "nc_save_dir      = cpuserver_data_FP + '/extracted_nc'\n",
    "output_dir       = cpuserver_data_FP + '/ASCAT/TUW/csv'\n",
    "output_dir_nc_3d = cpuserver_data_FP + '/ASCAT/TUW/nc_3d'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97763f31-dccd-4fbf-bb0a-e6015a65b42c",
   "metadata": {},
   "source": [
    "## 1. Import ASCAT data from raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d5a6e06-3595-40d9-b95d-0d96c13dc341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------------------+---------------+\n",
      "| Name           | Long Name                    | Units         |\n",
      "+================+==============================+===============+\n",
      "| lon            | location longitude           | degrees_east  |\n",
      "+----------------+------------------------------+---------------+\n",
      "| lat            | location latitude            | degrees_north |\n",
      "+----------------+------------------------------+---------------+\n",
      "| gpi            | grid point index             |               |\n",
      "+----------------+------------------------------+---------------+\n",
      "| cell           | cell number                  |               |\n",
      "+----------------+------------------------------+---------------+\n",
      "| land_flag      | land flag                    |               |\n",
      "+----------------+------------------------------+---------------+\n",
      "| committed_area | Committed soil moisture area |               |\n",
      "+----------------+------------------------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "# get the WARP5 Grid Information (GI) nc file\n",
    "ASCAT_FP = cpuserver_data_FP + '/ASCAT/TUW'\n",
    "GI_file_path = os.path.join(ASCAT_FP, 'warp5_grid/TUW_WARP5_grid_info_2_3.nc')\n",
    "# check the variable names and their units\n",
    "hData.get_nc_variable_names_units(GI_file_path);\n",
    "\n",
    "gpi = hData.get_variable_from_nc(GI_file_path, 'gpi')\n",
    "lat = hData.get_variable_from_nc(GI_file_path, 'lat')\n",
    "lon = hData.get_variable_from_nc(GI_file_path, 'lon')\n",
    "cell = hData.get_variable_from_nc(GI_file_path, 'cell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a957af8-b83c-4b3e-884b-e558c783d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the porosity data\n",
    "porosity_file_path = os.path.join(ASCAT_FP, 'static_layer/porosity.nc')\n",
    "por_gldas = hData.get_variable_from_nc(porosity_file_path, 'por_gldas')\n",
    "por_hwsd = hData.get_variable_from_nc(porosity_file_path, 'por_hwsd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a80c7ca6-8ecb-45d8-a30d-c925b91d78fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| Name                 | Long Name                               | Units                          |\n",
      "+======================+=========================================+================================+\n",
      "| row_size             | number of observations at this location |                                |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| lon                  | location longitude                      | degrees_east                   |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| lat                  | location latitude                       | degrees_north                  |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| alt                  | vertical distance above the surface     | m                              |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| location_id          |                                         |                                |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| location_description |                                         |                                |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| time                 | time of measurement                     | days since 1900-01-01 00:00:00 |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| sm                   | surface soil moisture                   | percentage                     |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| sm_noise             | surface soil moisture noise             | percentage                     |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| dir                  | orbit direction                         |                                |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| ssf                  | surface state flag                      |                                |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| sat_id               | satellite id                            |                                |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| proc_flag            | processing flag                         |                                |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| corr_flag            | correction flag                         |                                |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| conf_flag            | confidence flag                         |                                |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| slope40              | slope at 40 degree                      | dB/degree                      |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| slope40_noise        | slope at 40 degree noise                | dB/degree                      |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| curvature40          | curvature at 40 degree                  | dB/degree^2                    |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| curvature40_noise    | curvature at 40 degree noise            | dB/degree^2                    |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| sigma40              | backscatter at 40 degree                | dB                             |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n",
      "| sigma40_noise        | backscatter at 40 degree noise          | dB                             |\n",
      "+----------------------+-----------------------------------------+--------------------------------+\n"
     ]
    }
   ],
   "source": [
    "# ASCAT nc files\n",
    "nc_file_path = os.path.join(ASCAT_FP, 'h119')\n",
    "h119 = hData.get_file_list(nc_file_path, 'nc')\n",
    "nc_file_path = os.path.join(ASCAT_FP, 'h120')\n",
    "h120 = hData.get_file_list(nc_file_path, 'nc')\n",
    "ASCAT_file_path = h119+h120\n",
    "hData.get_nc_variable_names_units(ASCAT_file_path[0]);\n",
    "nof = len(ASCAT_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8804f2e-74ab-4574-be20-cbcbbd187b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_cell_numbers = []\n",
    "index_map = {}\n",
    "for index, path in enumerate(ASCAT_file_path):\n",
    "    identifier = path.split('_')[-1].split('.')[0]\n",
    "    if identifier not in unique_cell_numbers:\n",
    "        unique_cell_numbers.append(identifier)\n",
    "        index_map[identifier] = [index]\n",
    "    else:\n",
    "        index_map[identifier].append(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa0924-fa16-4d71-9b6f-7a65bf370061",
   "metadata": {},
   "source": [
    "## 1-1. Creat core csv files (should be updated yearly basis -- last updated Jun 1 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca8d40-1449-4cc5-8f35-91fe2b550f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single file operator\n",
    "geo_vars = ['row_size', 'lon', 'lat', 'location_id']\n",
    "obs_vars = ['time', 'sm', 'sm_noise', 'ssf', 'dir', 'proc_flag', 'corr_flag', 'conf_flag','sigma40', 'sigma40_noise']\n",
    "\n",
    "# Extract geolocation related data for a specific k\n",
    "for k in [2]:#range(unique_cell_numbers):\n",
    "\n",
    "    h_file_index = index_map.get(unique_cell_numbers[k], [])\n",
    "    \n",
    "    obs_df_list = []\n",
    "    for kk in h_file_index:\n",
    "        t_ASCAT_file_name = ASCAT_file_path[kk]\n",
    "        t_cell_number = t_ASCAT_file_name[-7:-3] # cell #\n",
    "        #t_h_number = t_ASCAT_file_name[-11:-8]   # H119 or H120\n",
    "    \n",
    "        print(t_ASCAT_file_name)\n",
    "        # Extract geolocation related data\n",
    "        geo_df = pd.DataFrame(columns=geo_vars).drop(columns='row_size')\n",
    "        t_row_size = hData.get_variable_from_nc(t_ASCAT_file_name, 'row_size')\n",
    "        t_lon = hData.get_variable_from_nc(t_ASCAT_file_name, 'lon')\n",
    "        t_lat = hData.get_variable_from_nc(t_ASCAT_file_name, 'lat')\n",
    "        t_location_id = hData.get_variable_from_nc(t_ASCAT_file_name, 'location_id')\n",
    "        \n",
    "        # Extract observation related data\n",
    "        t_time = hData.get_variable_from_nc(t_ASCAT_file_name, 'time')\n",
    "        t_sm = hData.get_variable_from_nc(t_ASCAT_file_name, 'sm')\n",
    "        t_sm_noise = hData.get_variable_from_nc(t_ASCAT_file_name, 'sm_noise')\n",
    "        t_ssf = hData.get_variable_from_nc(t_ASCAT_file_name, 'ssf')\n",
    "        t_dir = hData.get_variable_from_nc(t_ASCAT_file_name, 'dir')\n",
    "        t_proc_flag = hData.get_variable_from_nc(t_ASCAT_file_name, 'proc_flag')\n",
    "        t_corr_flag = hData.get_variable_from_nc(t_ASCAT_file_name, 'corr_flag')\n",
    "        t_conf_flag = hData.get_variable_from_nc(t_ASCAT_file_name, 'conf_flag')\n",
    "        t_sigma40 = hData.get_variable_from_nc(t_ASCAT_file_name, 'sigma40')\n",
    "        t_sigma40_noise = hData.get_variable_from_nc(t_ASCAT_file_name, 'sigma40_noise')\n",
    "        \n",
    "        t_dir = t_dir.astype(float)  # Convert orbit_dir to float\n",
    "        t_row_size = t_row_size[~np.isnan(t_row_size)]\n",
    "        obs_partial_df = pd.DataFrame(index=np.arange(t_row_size.sum()), columns=obs_vars+['lon', 'lat', 'location_id'])\n",
    "        \n",
    "        # Save them to dataframes\n",
    "        row_start = np.zeros(len(t_row_size), dtype=int)\n",
    "        row_end = np.zeros(len(t_row_size), dtype=int)\n",
    "    \n",
    "        for i in range(len(t_row_size)):\n",
    "    \n",
    "            geo_df.loc[i, 'lon'] = t_lon[i]\n",
    "            geo_df.loc[i, 'lat'] = t_lat[i]\n",
    "            geo_df.loc[i, 'location_id'] = t_location_id[i]\n",
    "                \n",
    "            if i == 0:\n",
    "                row_start[0] = 0\n",
    "                row_end[0] = t_row_size[0]\n",
    "            else:\n",
    "                row_start[i] = row_end[i-1]\n",
    "                row_end[i] = row_start[i] + t_row_size[i]\n",
    "        \n",
    "            for var in obs_vars:\n",
    "                obs_partial_df.loc[row_start[i]:row_end[i]-1, var] = globals()[f't_{var}'][row_start[i]:row_end[i]]\n",
    "    \n",
    "            obs_partial_df.loc[row_start[i]:row_end[i]-1, 'lon'] = geo_df.loc[i, 'lon']\n",
    "            obs_partial_df.loc[row_start[i]:row_end[i]-1, 'lat'] = geo_df.loc[i, 'lat']\n",
    "            obs_partial_df.loc[row_start[i]:row_end[i]-1, 'location_id'] = geo_df.loc[i, 'location_id']\n",
    "             \n",
    "        # Append the partial DataFrame to the list\n",
    "        obs_df_list.append(obs_partial_df)\n",
    "    \n",
    "    # Concatenate all partial DataFrames into a single DataFrame\n",
    "    obs_df = pd.concat(obs_df_list, ignore_index=True)\n",
    "    obs_df['local_time'] = hData.convert_to_local_time(obs_df)\n",
    "    obs_df.to_csv(os.path.join(output_dir, 'h119_h120_'+t_cell_number+'.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca42369-f970-4de3-8bf2-dd17766e4ee9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Parallelize the execution of the loop using joblib\n",
    "# Function to process data for a specific range of k values\n",
    "def process_data(k_range, unique_cell_numbers):\n",
    "    for k in k_range:\n",
    "        h_file_index = index_map.get(unique_cell_numbers[k], [])\n",
    "\n",
    "        obs_df_list = []\n",
    "        for kk in h_file_index:\n",
    "            t_ASCAT_file_name = ASCAT_file_path[kk]\n",
    "            t_cell_number = t_ASCAT_file_name[-7:-3]  # cell #\n",
    "            #t_h_number = t_ASCAT_file_name[-11:-8]   # H119 or H120\n",
    "\n",
    "            print(t_ASCAT_file_name)\n",
    "            # Extract geolocation related data\n",
    "            geo_df = pd.DataFrame(columns=geo_vars).drop(columns='row_size')\n",
    "            \n",
    "            t_row_size = hData.get_variable_from_nc(t_ASCAT_file_name, 'row_size')\n",
    "            t_lon = hData.get_variable_from_nc(t_ASCAT_file_name, 'lon')\n",
    "            t_lat = hData.get_variable_from_nc(t_ASCAT_file_name, 'lat')\n",
    "            t_location_id = hData.get_variable_from_nc(t_ASCAT_file_name, 'location_id')\n",
    "            \n",
    "            # Extract observation related data\n",
    "            for var in obs_vars:\n",
    "                globals()[f't_{var}'] = hData.get_variable_from_nc(t_ASCAT_file_name, var)\n",
    "                \n",
    "            t_time = hData.get_variable_from_nc(t_ASCAT_file_name, 'time')\n",
    "            t_sm = hData.get_variable_from_nc(t_ASCAT_file_name, 'sm')\n",
    "            t_sm_noise = hData.get_variable_from_nc(t_ASCAT_file_name, 'sm_noise')\n",
    "            t_ssf = hData.get_variable_from_nc(t_ASCAT_file_name, 'ssf')\n",
    "            t_dir = hData.get_variable_from_nc(t_ASCAT_file_name, 'dir')\n",
    "            t_proc_flag = hData.get_variable_from_nc(t_ASCAT_file_name, 'proc_flag')\n",
    "            t_corr_flag = hData.get_variable_from_nc(t_ASCAT_file_name, 'corr_flag')\n",
    "            t_conf_flag = hData.get_variable_from_nc(t_ASCAT_file_name, 'conf_flag')\n",
    "            t_sigma40 = hData.get_variable_from_nc(t_ASCAT_file_name, 'sigma40')\n",
    "            t_sigma40_noise = hData.get_variable_from_nc(t_ASCAT_file_name, 'sigma40_noise')\n",
    "            \n",
    "            t_dir = t_dir.astype(float)  # Convert orbit_dir to float\n",
    "            t_row_size = t_row_size[~np.isnan(t_row_size)]\n",
    "            obs_partial_df = pd.DataFrame(index=np.arange(t_row_size.sum()), columns=obs_vars+['lon', 'lat', 'location_id'])\n",
    "\n",
    "            # Save them to dataframes\n",
    "            row_start = np.zeros(len(t_row_size), dtype=int)\n",
    "            row_end = np.zeros(len(t_row_size), dtype=int)\n",
    "\n",
    "            for i in range(len(t_row_size)):\n",
    "                geo_df.loc[i, 'lon'] = t_lon[i]\n",
    "                geo_df.loc[i, 'lat'] = t_lat[i]\n",
    "                geo_df.loc[i, 'location_id'] = t_location_id[i]\n",
    "\n",
    "                if i == 0:\n",
    "                    row_start[0] = 0\n",
    "                    row_end[0] = t_row_size[0]\n",
    "                else:\n",
    "                    row_start[i] = row_end[i-1]\n",
    "                    row_end[i] = row_start[i] + t_row_size[i]\n",
    "\n",
    "                for var in obs_vars:\n",
    "                    obs_partial_df.loc[row_start[i]:row_end[i]-1, var] = globals()[f't_{var}'][row_start[i]:row_end[i]]\n",
    "\n",
    "                obs_partial_df.loc[row_start[i]:row_end[i]-1, 'lon'] = geo_df.loc[i, 'lon']\n",
    "                obs_partial_df.loc[row_start[i]:row_end[i]-1, 'lat'] = geo_df.loc[i, 'lat']\n",
    "                obs_partial_df.loc[row_start[i]:row_end[i]-1, 'location_id'] = geo_df.loc[i, 'location_id']\n",
    "\n",
    "            # Append the partial DataFrame to the list\n",
    "            obs_df_list.append(obs_partial_df)\n",
    "\n",
    "        # Concatenate all partial DataFrames into a single DataFrame\n",
    "        obs_df = pd.concat(obs_df_list, ignore_index=True)\n",
    "        obs_df['local_time'] = hData.convert_to_local_time(obs_df)\n",
    "        #obs_df.to_csv(os.path.join(output_dir, 't_h119_h120_' + t_cell_number + '.csv'))\n",
    "        obs_df.to_csv(os.path.join(output_dir, 'h119_h120_' + t_cell_number + '.csv'))\n",
    "\n",
    "# Number of processors to use\n",
    "n_processors = 48\n",
    "\n",
    "# Divide the range into chunks based on the number of processors\n",
    "chunk_size = len(unique_cell_numbers) // n_processors\n",
    "ranges = [range(i * chunk_size, (i + 1) * chunk_size) for i in range(n_processors)]\n",
    "\n",
    "# If there are remaining elements, add them to the last chunk\n",
    "if len(unique_cell_numbers) % n_processors != 0:\n",
    "    ranges[-1] = range((n_processors - 1) * chunk_size, len(unique_cell_numbers))\n",
    "\n",
    "# Run the processing in parallel\n",
    "Parallel(n_jobs=n_processors)(delayed(process_data)(k_range, unique_cell_numbers) for k_range in ranges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea84c966-343f-4990-b0e8-db2e7eab3fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_resol = 0.25\n",
    "resampled_name = 'R_Noah_025'\n",
    "target_lon, target_lat = hGrid.generate_lon_lat_eqdgrid(target_resol)\n",
    "am_pm = ['pm', 'am']\n",
    "start_year = 2023\n",
    "end_year   = 2023\n",
    "num_days   = (datetime(end_year+1,1,1) - datetime(start_year,1,1)).days\n",
    "cutoff_datetime = pd.to_datetime(str(end_year+1)+'-01-01 00:00:00')\n",
    "\n",
    "csv_folder = os.path.join(ASCAT_FP, 'csv')\n",
    "csv_file_path = hData.get_file_list(csv_folder, 'csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e96291e-b381-447c-af82-3d844aac76d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 740\n",
    "orbit = 0 # 0: ascending (pm; 21:30) / 1: descending (am; 9:30)\n",
    "\n",
    "t_csv_file_name = csv_file_path[i]\n",
    "print(t_csv_file_name)\n",
    "t_cell_number   = t_csv_file_name[-8:-4]\n",
    "t_lat           = pd.read_csv(t_csv_file_name, usecols=['lat'])\n",
    "t_lon           = pd.read_csv(t_csv_file_name, usecols=['lon'])\n",
    "t_local_time    = pd.read_csv(t_csv_file_name, usecols=['local_time'])\n",
    "t_time          = pd.read_csv(t_csv_file_name, usecols=['time'])\n",
    "t_location_id   = pd.read_csv(t_csv_file_name, usecols=['location_id'])\n",
    "t_sm            = pd.read_csv(t_csv_file_name, usecols=['sm'])\n",
    "t_conf_flag     = pd.read_csv(t_csv_file_name, usecols=['conf_flag'])\n",
    "t_dir           = pd.read_csv(t_csv_file_name, usecols=['dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f906a96-a836-4073-83bb-137a4fd5b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert fractional days to datetime\n",
    "base_date = datetime(1900, 1, 1)\n",
    "t_local_time['datetime'] = t_local_time['local_time'].apply(lambda x: base_date + timedelta(days=x))\n",
    "\n",
    "# Define the base year for DOY calculation\n",
    "base_year = start_year\n",
    "# Calculate DOY\n",
    "t_local_time['doy'] = t_local_time['datetime'].apply(lambda x: hASCAT_TUW.calculate_doy(x, base_year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02e125e-a35a-497b-ba1c-58fc0fde19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find closest index of the current cell data\n",
    "t_ll_idx = hData.find_closest_index(target_lon, target_lat, [np.min(t_lon), np.min(t_lat)])\n",
    "t_lr_idx = hData.find_closest_index(target_lon, target_lat, [np.max(t_lon), np.min(t_lat)])\n",
    "t_ul_idx = hData.find_closest_index(target_lon, target_lat, [np.min(t_lon), np.max(t_lat)])\n",
    "t_ur_idx = hData.find_closest_index(target_lon, target_lat, [np.max(t_lon), np.max(t_lat)])\n",
    "\n",
    "# Create target data frames for raw and QC data\n",
    "t_target_frame_gldas       = hData.create_3d_object_array(t_ll_idx[0]-t_ul_idx[0]+1, t_lr_idx[1]-t_ll_idx[1]+1, num_days+1) #+1 because python starts from 0\n",
    "t_target_frame_hwsd        = hData.create_3d_object_array(t_ll_idx[0]-t_ul_idx[0]+1, t_lr_idx[1]-t_ll_idx[1]+1, num_days+1) \n",
    "t_final_target_frame_gldas = hData.create_3d_np_array(t_ll_idx[0]-t_ul_idx[0]+1, t_lr_idx[1]-t_ll_idx[1]+1, num_days+1)\n",
    "t_final_target_frame_hwsd  = hData.create_3d_np_array(t_ll_idx[0]-t_ul_idx[0]+1, t_lr_idx[1]-t_ll_idx[1]+1, num_days+1)\n",
    "\n",
    "t_target_frame_gldas_QC       = hData.create_3d_object_array(t_ll_idx[0]-t_ul_idx[0]+1, t_lr_idx[1]-t_ll_idx[1]+1, num_days+1)\n",
    "t_target_frame_hwsd_QC        = hData.create_3d_object_array(t_ll_idx[0]-t_ul_idx[0]+1, t_lr_idx[1]-t_ll_idx[1]+1, num_days+1) \n",
    "t_final_target_frame_gldas_QC = hData.create_3d_np_array(t_ll_idx[0]-t_ul_idx[0]+1, t_lr_idx[1]-t_ll_idx[1]+1, num_days+1)\n",
    "t_final_target_frame_hwsd_QC  = hData.create_3d_np_array(t_ll_idx[0]-t_ul_idx[0]+1, t_lr_idx[1]-t_ll_idx[1]+1, num_days+1)\n",
    "\n",
    "t_target_lon   = target_lon[t_ul_idx[0]:t_ll_idx[0]+1, t_ll_idx[1]:t_lr_idx[1]+1]\n",
    "t_target_lat   = target_lat[t_ul_idx[0]:t_ll_idx[0]+1, t_ll_idx[1]:t_lr_idx[1]+1]\n",
    "\n",
    "# Create porosity data frames for gldas and hwsd(just check for the difference)\n",
    "t_por_gldas = hData.create_3d_np_array(t_ll_idx[0]-t_ul_idx[0]+1, t_lr_idx[1]-t_ll_idx[1]+1, 0)\n",
    "t_por_hwsd  = hData.create_3d_np_array(t_ll_idx[0]-t_ul_idx[0]+1, t_lr_idx[1]-t_ll_idx[1]+1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1752c2f5-de53-4626-afb3-7aa02749f574",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t_unique_location_id = pd.DataFrame(np.unique(t_location_id['location_id']).astype('int'), columns=['unique_location_id'])\n",
    "for ti in range(len(t_unique_location_id)):\n",
    "    t_lat_idx = hData.find_closest_index(t_target_lon, t_target_lat, [lon[t_unique_location_id.unique_location_id[ti]], lat[t_unique_location_id.unique_location_id[ti]]])[0]\n",
    "    t_lon_idx = hData.find_closest_index(t_target_lon, t_target_lat, [lon[t_unique_location_id.unique_location_id[ti]], lat[t_unique_location_id.unique_location_id[ti]]])[1]\n",
    "    t_unique_location_id.loc[ti, 'lat_idx'] = int(t_lat_idx)\n",
    "    t_unique_location_id.loc[ti, 'lon_idx'] = int(t_lon_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcd675d-e089-4591-ac0f-09c3489a4602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create gldas and hwsd porosity map for comparison\n",
    "t_por_gldas[t_unique_location_id['lat_idx'].astype('int'), t_unique_location_id['lon_idx'].astype('int')] = por_gldas[t_unique_location_id['unique_location_id']]\n",
    "t_por_hwsd[t_unique_location_id['lat_idx'].astype('int'), t_unique_location_id['lon_idx'].astype('int')]  = por_hwsd[t_unique_location_id['unique_location_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "930e75d9-5f64-434d-9422-cdbbc60cfda0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# QC vs non-QC process\n",
    "t_data_filter    = (t_local_time['datetime'] < cutoff_datetime) & (t_dir['dir'] == orbit) & (t_local_time['doy']>0)\n",
    "t_data_filter_QC = t_data_filter & (t_conf_flag['conf_flag'] != 0) \n",
    "\n",
    "tt_sm = t_sm.loc[t_data_filter].reset_index(drop=True)\n",
    "tt_local_time = t_local_time[t_data_filter].reset_index(drop=True)\n",
    "tt_location_id = t_location_id[t_data_filter].reset_index(drop=True)\n",
    "\n",
    "tt_sm_QC          = t_sm.loc[t_data_filter_QC].reset_index(drop=True)\n",
    "tt_local_time_QC  = t_local_time[t_data_filter_QC].reset_index(drop=True)\n",
    "tt_location_id_QC = t_location_id[t_data_filter_QC].reset_index(drop=True)\n",
    "\n",
    "for si in tqdm(range(len(tt_sm))):\n",
    "    tt_lat_idx   = t_unique_location_id[t_unique_location_id['unique_location_id'] == tt_location_id.iloc[si][0]].lat_idx.iloc[0].astype('int')\n",
    "    tt_lon_idx   = t_unique_location_id[t_unique_location_id['unique_location_id'] == tt_location_id.iloc[si][0]].lon_idx.iloc[0].astype('int')\n",
    "    tt_por_gldas = por_gldas[tt_location_id.iloc[si][0].astype('int')]\n",
    "    tt_por_hwsd  = por_hwsd[tt_location_id.iloc[si][0].astype('int')]\n",
    "    tt_doy       = tt_local_time.iloc[si]['doy']\n",
    "    \n",
    "    t_target_frame_gldas[tt_lat_idx, tt_lon_idx, tt_doy].append(tt_sm.iloc[si]['sm']*tt_por_gldas)\n",
    "    t_target_frame_hwsd[tt_lat_idx, tt_lon_idx, tt_doy].append(tt_sm.iloc[si]['sm']*tt_por_hwsd)\n",
    "\n",
    "for si in tqdm(range(len(tt_sm_QC))):\n",
    "    tt_lat_idx   = t_unique_location_id[t_unique_location_id['unique_location_id'] == tt_location_id_QC.iloc[si][0]].lat_idx.iloc[0].astype('int')\n",
    "    tt_lon_idx   = t_unique_location_id[t_unique_location_id['unique_location_id'] == tt_location_id_QC.iloc[si][0]].lon_idx.iloc[0].astype('int')\n",
    "    tt_por_gldas = por_gldas[tt_location_id_QC.iloc[si][0].astype('int')]\n",
    "    tt_por_gldas = por_hwsd[tt_location_id_QC.iloc[si][0].astype('int')]\n",
    "    tt_doy       = tt_local_time_QC.iloc[si]['doy']\n",
    "    \n",
    "    t_target_frame_gldas_QC[tt_lat_idx, tt_lon_idx, tt_doy].append(tt_sm_QC.iloc[si]['sm']*tt_por_gldas)\n",
    "    t_target_frame_hwsd_QC[tt_lat_idx, tt_lon_idx, tt_doy].append(tt_sm_QC.iloc[si]['sm']*tt_por_hwsd)\n",
    "\n",
    "t_final_target_frame_gldas    = hData.object_array_to_np(t_target_frame_gldas, t_final_target_frame_gldas)\n",
    "t_final_target_frame_hwsd     = hData.object_array_to_np(t_target_frame_hwsd, t_final_target_frame_hwsd)\n",
    "t_final_target_frame_gldas_QC = hData.object_array_to_np(t_target_frame_gldas_QC, t_final_target_frame_gldas_QC)\n",
    "t_final_target_frame_hwsd_QC  = hData.object_array_to_np(t_target_frame_hwsd_QC, t_final_target_frame_hwsd_QC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045576a6-39ab-435b-9d6e-94454784e4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_nc_file_name = 'ASCAT_TUW_'+str(start_year)+'_'+str(end_year)+'_'+am_pm[orbit]+'_'+resampled_name+'_cell_'+t_cell_number+'.nc'\n",
    "#= os.path.join(output_dir_nc_3d, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63500e2f-8fb2-40e4-ac68-3b9250b303da",
   "metadata": {},
   "outputs": [],
   "source": [
    "hData.create_netcdf_file(\n",
    "        nc_file    = t_nc_file_name,\n",
    "        latitude   = t_target_lat,\n",
    "        longitude  = t_target_lon,\n",
    "        Resampled_ASCAT_SM_gldas    = t_final_target_frame_gldas,\n",
    "        Resampled_ASCAT_SM_gldas_QC = t_final_target_frame_gldas_QC,\n",
    "        Resampled_ASCAT_SM_hwsd    = t_final_target_frame_hwsd,\n",
    "        Resampled_ASCAT_SM_hwsd_QC = t_final_target_frame_hwsd_QC,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbcc7d8-eb11-4198-9f74-52a8e71448b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(t_final_target_frame_gldas[1,6,:],'x')\n",
    "plt.plot(t_final_target_frame_gldas_QC[1,6,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec0e4ca-43b2-4c59-b6a0-542021bd818a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttt = np.nanmean(t_final_target_frame, axis=2)\n",
    "#bounds = [-180, 180, -90, 90]\n",
    "hPlot.plot_map(t_target_lon, t_target_lat, ttt, 0, 100, projection='PlateCarree')\n",
    "ttt = np.nanmean(t_final_target_frame_QC, axis=2)\n",
    "hPlot.plot_map(t_target_lon, t_target_lat, ttt, 0, 100, projection='PlateCarree')\n",
    "hPlot.plot_map(t_target_lon, t_target_lat, t_por_gldas, 0.3, 1, projection='PlateCarree')\n",
    "hPlot.plot_map(t_target_lon, t_target_lat, t_por_hwsd, 0.3, 1, projection='PlateCarree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b831aa-0a04-4cdb-b9ea-b573ef06b485",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
