{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "import datetime\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import importlib\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_FP = '/home/subin/data'\n",
    "cpuserver_data_FP = '/home/subin/cpuserver_data'\n",
    "sys.path.append(base_FP + '/python_modules')\n",
    "\n",
    "import develop_HydroAI.HydroAI.TC_like as hTCL\n",
    "import develop_HydroAI.HydroAI.Vectorization as hVec\n",
    "import matplotlib.pyplot as plt\n",
    "importlib.reload(hTCL);\n",
    "importlib.reload(hVec);\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Define your directory where to save nc files\n",
    "nc_save_dir = cpuserver_data_FP + '/extracted_nc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New Functions for TCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETC_vec(X, Y, Z, nod_th=30, corr_th=0):\n",
    "    '''Edit TCA_vec_old without scaling the data'''\n",
    "\n",
    "    # 0. check the NaN and fill with NaN if any of X,Y, and Z value is nan.\n",
    "    combined_nan_mask = np.isnan(X) | np.isnan(Y) | np.isnan(Z)\n",
    "    X[combined_nan_mask] = np.nan\n",
    "    Y[combined_nan_mask] = np.nan\n",
    "    Z[combined_nan_mask] = np.nan\n",
    "\n",
    "    # 1. calculation for the originial data\n",
    "    # Calculate covariance\n",
    "    cov_corr_results = hVec.cov_corr_three(X, Y, Z)\n",
    "    covXY = cov_corr_results.get('covXY')\n",
    "    covXZ = cov_corr_results.get('covXZ')\n",
    "    covYZ = cov_corr_results.get('covYZ')\n",
    "\n",
    "    corrXY = cov_corr_results.get('corrXY')\n",
    "    corrXZ = cov_corr_results.get('corrXZ')\n",
    "    corrYZ = cov_corr_results.get('corrYZ')\n",
    "\n",
    "    # 2. Vectorized TC calculatio\n",
    "    # No-Scale the data\n",
    "    Xs = X \n",
    "    Ys = Y\n",
    "    Zs = Z\n",
    "    X=[]; Y=[]; Z=[];\n",
    "\n",
    "    # Calculate covariance with scaled Xs, Ys, and Zs\n",
    "    cov_corr_results_s = hVec.cov_corr_three(Xs, Ys, Zs)\n",
    "\n",
    "    covXXs = cov_corr_results_s.get('covXX')\n",
    "    covYYs = cov_corr_results_s.get('covYY')\n",
    "    covZZs = cov_corr_results_s.get('covZZ')\n",
    "    covXYs = cov_corr_results_s.get('covXY')\n",
    "    covXZs = cov_corr_results_s.get('covXZ')\n",
    "    covYZs = cov_corr_results_s.get('covYZ')\n",
    "\n",
    "    # Calculate correlation with scaled Xs, Ys, and Zs\n",
    "    corrXYs = cov_corr_results_s.get('corrXYs')\n",
    "    corrXZs = cov_corr_results_s.get('corrXZs')\n",
    "    corrYZs = cov_corr_results_s.get('corrYZs')\n",
    "\n",
    "    var_Xserr = covXXs - covXYs*covXZs/covYZs\n",
    "    var_Yserr = covYYs - covXYs*covYZs/covXZs\n",
    "    var_Zserr = covZZs - covXZs*covYZs/covXYs\n",
    "\n",
    "    # Calcuate TC numbers\n",
    "    SNR_Xs =  (covXYs * covXZs / covYZs) / var_Xserr\n",
    "    SNR_Ys =  (covXYs * covYZs / covXZs) / var_Yserr\n",
    "    SNR_Zs =  (covXZs * covYZs / covXYs) / var_Zserr\n",
    "\n",
    "    R_XYs = 1 / ((1 + 1/SNR_Xs) * (1 + 1/SNR_Ys)) ** 0.5\n",
    "    R_XZs = 1 / ((1 + 1/SNR_Xs) * (1 + 1/SNR_Zs)) ** 0.5\n",
    "    R_YZs = 1 / ((1 + 1/SNR_Ys) * (1 + 1/SNR_Zs)) ** 0.5\n",
    "\n",
    "    fMSE_Xs = 1 / (1 + SNR_Xs)\n",
    "    fMSE_Ys = 1 / (1 + SNR_Ys)\n",
    "    fMSE_Zs = 1 / (1 + SNR_Zs)\n",
    "\n",
    "    R_XXs = 1 / (1 + 1/SNR_Xs)\n",
    "    R_YYs = 1 / (1 + 1/SNR_Ys)\n",
    "    R_ZZs = 1 / (1 + 1/SNR_Zs)\n",
    "\n",
    "    SNRdb_Xs = 10 * np.log10(SNR_Xs)\n",
    "    SNRdb_Ys = 10 * np.log10(SNR_Ys)\n",
    "    SNRdb_Zs = 10 * np.log10(SNR_Zs)\n",
    "\n",
    "    VAR_err = {'x': var_Xserr, 'y': var_Yserr, 'z': var_Zserr}\n",
    "    SNR = {'x': SNR_Xs, 'y': SNR_Ys, 'z': SNR_Zs}\n",
    "    SNRdb = {'x': SNRdb_Xs, 'y': SNRdb_Ys, 'z': SNRdb_Zs}\n",
    "    R = {'x': R_XXs, 'y': R_YYs, 'z': R_ZZs}\n",
    "    fMSE = {'x': fMSE_Xs, 'y': fMSE_Ys, 'z': fMSE_Zs}\n",
    "\n",
    "    # 3. set the flags\n",
    "    # flag on non-scaled data\n",
    "    condition_corr = (corrXY < corr_th) | (corrXZ < corr_th) | (corrYZ < corr_th) #flag 1\n",
    "\n",
    "    # falg on scaled data\n",
    "    condition_n_valid = np.sum(~np.isnan(Xs) & ~np.isnan(Ys) & ~np.isnan(Zs), axis=2) < nod_th #flag 2\n",
    "    condition_fMSE = (fMSE_Xs < 0) | (fMSE_Ys < 0) | (fMSE_Zs < 0) | (fMSE_Xs > 1) | (fMSE_Ys > 1) | (fMSE_Zs > 1) #flag 3\n",
    "    condition_negative_vars_err  = (var_Xserr < 0) | (var_Yserr < 0) | (var_Zserr < 0) #flag 4\n",
    "\n",
    "    flags = {'condition_corr': condition_corr,\n",
    "            'condition_n_valid': condition_n_valid,\n",
    "            'condition_fMSE': condition_fMSE,\n",
    "            'condition_negative_vars_err': condition_negative_vars_err}\n",
    "\n",
    "    return VAR_err, SNR, SNRdb, R, fMSE, flags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TCA_vec(X, Y, Z, nod_th=30, corr_th=0):\n",
    "    original_shape = X.shape[:-1]  # Get the shape without the last dimension\n",
    "    original_size = np.prod(original_shape)\n",
    "\n",
    "    # 0. Check for NaNs and ensure that any NaNs are consistent across datasets\n",
    "    combined_nan_mask = np.isnan(X) | np.isnan(Y) | np.isnan(Z)\n",
    "    X[combined_nan_mask] = np.nan\n",
    "    Y[combined_nan_mask] = np.nan\n",
    "    Z[combined_nan_mask] = np.nan\n",
    "\n",
    "    # Flatten the data to 2D arrays\n",
    "    X_flat = X.reshape(-1, X.shape[-1])\n",
    "    Y_flat = Y.reshape(-1, Y.shape[-1])\n",
    "    Z_flat = Z.reshape(-1, Z.shape[-1])\n",
    "\n",
    "    # Initialize arrays to store results\n",
    "    errVar_ETC = np.full((original_size, 3), np.nan)\n",
    "    rho2_ETC = np.full((original_size, 3), np.nan)\n",
    "    SNR = np.full((original_size, 3), np.nan)\n",
    "    SNRdb = np.full((original_size, 3), np.nan)\n",
    "\n",
    "    # Iterate over each time series (row)\n",
    "    for i in range(original_size):\n",
    "        y = np.column_stack((X_flat[i], Y_flat[i], Z_flat[i]))  # Shape: (T, 3)\n",
    "\n",
    "        # Remove NaNs\n",
    "        y = y[~np.isnan(y).any(axis=1)]\n",
    "\n",
    "        # Check that there are enough valid observations\n",
    "        if y.shape[0] < nod_th:\n",
    "            continue  # Skip if not enough data\n",
    "\n",
    "        # Compute covariance matrix\n",
    "        Q_hat = np.cov(y, rowvar=False)\n",
    "\n",
    "        # Ensure covariance matrix is full rank\n",
    "        if np.linalg.matrix_rank(Q_hat) < 3:\n",
    "            continue  # Skip if covariance matrix is singular\n",
    "\n",
    "        # Calculate correlation coefficients\n",
    "        try:\n",
    "            rho_ETC = np.zeros(3)\n",
    "            rho_ETC[0] = np.sqrt(Q_hat[0,1]*Q_hat[0,2]/(Q_hat[0,0]*Q_hat[1,2]))\n",
    "            rho_ETC[1] = np.sign(Q_hat[0,2]*Q_hat[1,2]) * np.sqrt(Q_hat[0,1]*Q_hat[1,2]/(Q_hat[1,1]*Q_hat[0,2]))\n",
    "            rho_ETC[2] = np.sign(Q_hat[0,1]*Q_hat[1,2]) * np.sqrt(Q_hat[0,2]*Q_hat[1,2]/(Q_hat[2,2]*Q_hat[0,1]))\n",
    "\n",
    "            rho2_ETC[i, :] = rho_ETC**2\n",
    "\n",
    "            # Calculate error variances\n",
    "            errVar_ETC[i, 0] = Q_hat[0,0] - Q_hat[0,1]*Q_hat[0,2]/Q_hat[1,2]\n",
    "            errVar_ETC[i, 1] = Q_hat[1,1] - Q_hat[0,1]*Q_hat[1,2]/Q_hat[0,2]\n",
    "            errVar_ETC[i, 2] = Q_hat[2,2] - Q_hat[0,2]*Q_hat[1,2]/Q_hat[0,1]\n",
    "\n",
    "            # Calculate SNR\n",
    "            SNR[i, :] = (rho2_ETC[i, :]) / (1 - rho2_ETC[i, :])\n",
    "\n",
    "            # Calculate SNR in dB\n",
    "            SNRdb[i, :] = 10 * np.log10(SNR[i, :])\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle any mathematical errors (e.g., division by zero)\n",
    "            continue\n",
    "\n",
    "    # Reshape results back to original shape\n",
    "    VAR_err = {\n",
    "        'x': errVar_ETC[:, 0].reshape(original_shape),\n",
    "        'y': errVar_ETC[:, 1].reshape(original_shape),\n",
    "        'z': errVar_ETC[:, 2].reshape(original_shape)\n",
    "    }\n",
    "    SNR = {\n",
    "        'x': SNR[:, 0].reshape(original_shape),\n",
    "        'y': SNR[:, 1].reshape(original_shape),\n",
    "        'z': SNR[:, 2].reshape(original_shape)\n",
    "    }\n",
    "    SNRdb = {\n",
    "        'x': SNRdb[:, 0].reshape(original_shape),\n",
    "        'y': SNRdb[:, 1].reshape(original_shape),\n",
    "        'z': SNRdb[:, 2].reshape(original_shape)\n",
    "    }\n",
    "    R = {\n",
    "        'x': rho2_ETC[:, 0].reshape(original_shape),\n",
    "        'y': rho2_ETC[:, 1].reshape(original_shape),\n",
    "        'z': rho2_ETC[:, 2].reshape(original_shape)\n",
    "    }\n",
    "    fMSE = {\n",
    "        'x': (1 - rho2_ETC[:, 0]).reshape(original_shape),\n",
    "        'y': (1 - rho2_ETC[:, 1]).reshape(original_shape),\n",
    "        'z': (1 - rho2_ETC[:, 2]).reshape(original_shape)\n",
    "    }\n",
    "\n",
    "    # Set the flags\n",
    "    condition_corr = ((R['x'] < corr_th) | (R['y'] < corr_th) | (R['z'] < corr_th))\n",
    "    condition_n_valid = np.sum(~np.isnan(X) & ~np.isnan(Y) & ~np.isnan(Z), axis=-1) < nod_th\n",
    "    condition_fMSE = ((fMSE['x'] < 0) | (fMSE['y'] < 0) | (fMSE['z'] < 0) | \n",
    "                      (fMSE['x'] > 1) | (fMSE['y'] > 1) | (fMSE['z'] > 1))\n",
    "    condition_negative_vars_err = (errVar_ETC < 0).any(axis=1).reshape(original_shape)\n",
    "\n",
    "    flags = {\n",
    "        'condition_corr': condition_corr,\n",
    "        'condition_n_valid': condition_n_valid,\n",
    "        'condition_fMSE': condition_fMSE,\n",
    "        'condition_negative_vars_err': condition_negative_vars_err\n",
    "    }\n",
    "\n",
    "    return VAR_err, SNR, SNRdb, R, fMSE, flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TCA_vec_cannot_calculate_nan(X, Y, Z, nod_th=30, corr_th=0):\n",
    "    '''New developed TCA_vec function but cannot calculate when there is NaN in the data'''\n",
    "    original_shape = X.shape[:-1]  # Get the shape without the last dimension\n",
    "\n",
    "    # 0. Check for NaNs and ensure that any NaNs are consistent across datasets\n",
    "    combined_nan_mask = np.isnan(X) | np.isnan(Y) | np.isnan(Z)\n",
    "    X[combined_nan_mask] = np.nan\n",
    "    Y[combined_nan_mask] = np.nan\n",
    "    Z[combined_nan_mask] = np.nan\n",
    "\n",
    "    # Remove completely NaN slices (if data is 3D)\n",
    "    valid_mask = ~np.isnan(X).all(axis=2) & ~np.isnan(Y).all(axis=2) & ~np.isnan(Z).all(axis=2)\n",
    "    X = X[valid_mask]\n",
    "    Y = Y[valid_mask]\n",
    "    Z = Z[valid_mask]\n",
    "\n",
    "    # 1. Flatten the data to 2D arrays if necessary\n",
    "    X_flat = X.reshape(-1, X.shape[-1])\n",
    "    Y_flat = Y.reshape(-1, Y.shape[-1])\n",
    "    Z_flat = Z.reshape(-1, Z.shape[-1])\n",
    "\n",
    "    # Remove rows with NaNs\n",
    "    valid_rows = ~np.isnan(X_flat).any(axis=1) & ~np.isnan(Y_flat).any(axis=1) & ~np.isnan(Z_flat).any(axis=1)\n",
    "    X_flat = X_flat[valid_rows]\n",
    "    Y_flat = Y_flat[valid_rows]\n",
    "    Z_flat = Z_flat[valid_rows]\n",
    "\n",
    "    # Combine the data into a single array\n",
    "    data = np.stack((X_flat, Y_flat, Z_flat), axis=1)  # Shape: (N, 3, T)\n",
    "\n",
    "    # Initialize arrays to store results\n",
    "    N = data.shape[0]\n",
    "    errVar_ETC = np.zeros((N, 3))\n",
    "    rho2_ETC = np.zeros((N, 3))\n",
    "    SNR = np.zeros((N, 3))\n",
    "    SNRdb = np.zeros((N, 3))\n",
    "\n",
    "    # Iterate over each time series (row)\n",
    "    for i in range(N):\n",
    "        y = data[i, :, :].T  # Shape: (T, 3)\n",
    "\n",
    "        # Check that there are enough valid observations\n",
    "        if y.shape[0] < nod_th:\n",
    "            continue  # Skip if not enough data\n",
    "\n",
    "        # Remove any remaining NaNs\n",
    "        if np.isnan(y).any():\n",
    "            continue  # Skip if there are NaNs\n",
    "\n",
    "        # Compute covariance matrix\n",
    "        Q_hat = np.cov(y, rowvar=False)\n",
    "\n",
    "        # Ensure covariance matrix is full rank\n",
    "        if np.linalg.matrix_rank(Q_hat) < 3:\n",
    "            continue  # Skip if covariance matrix is singular\n",
    "\n",
    "        # Calculate correlation coefficients\n",
    "        try:\n",
    "            rho_ETC = np.zeros(3)\n",
    "            rho_ETC[0] = np.sqrt(Q_hat[0,1]*Q_hat[0,2]/(Q_hat[0,0]*Q_hat[1,2]))\n",
    "            rho_ETC[1] = np.sign(Q_hat[0,2]*Q_hat[1,2]) * np.sqrt(Q_hat[0,1]*Q_hat[1,2]/(Q_hat[1,1]*Q_hat[0,2]))\n",
    "            rho_ETC[2] = np.sign(Q_hat[0,1]*Q_hat[1,2]) * np.sqrt(Q_hat[0,2]*Q_hat[1,2]/(Q_hat[2,2]*Q_hat[0,1]))\n",
    "\n",
    "            rho2_ETC[i, :] = rho_ETC**2\n",
    "\n",
    "            # Calculate error variances\n",
    "            errVar_ETC[i, 0] = Q_hat[0,0] - Q_hat[0,1]*Q_hat[0,2]/Q_hat[1,2]\n",
    "            errVar_ETC[i, 1] = Q_hat[1,1] - Q_hat[0,1]*Q_hat[1,2]/Q_hat[0,2]\n",
    "            errVar_ETC[i, 2] = Q_hat[2,2] - Q_hat[0,2]*Q_hat[1,2]/Q_hat[0,1]\n",
    "\n",
    "            # Calculate SNR\n",
    "            SNR[i, :] = (rho2_ETC[i, :]) / (1 - rho2_ETC[i, :])\n",
    "\n",
    "            # Calculate SNR in dB\n",
    "            SNRdb[i, :] = 10 * np.log10(SNR[i, :])\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle any mathematical errors (e.g., division by zero)\n",
    "            continue\n",
    "\n",
    "    # Prepare outputs\n",
    "    \n",
    "    VAR_err = {\n",
    "        'x': errVar_ETC[:, 0].reshape(original_shape),\n",
    "        'y': errVar_ETC[:, 1].reshape(original_shape),\n",
    "        'z': errVar_ETC[:, 2].reshape(original_shape)\n",
    "    }\n",
    "    SNR = {\n",
    "        'x': SNR[:, 0].reshape(original_shape),\n",
    "        'y': SNR[:, 1].reshape(original_shape),\n",
    "        'z': SNR[:, 2].reshape(original_shape)\n",
    "    }\n",
    "    SNRdb = {\n",
    "        'x': SNRdb[:, 0].reshape(original_shape),\n",
    "        'y': SNRdb[:, 1].reshape(original_shape),\n",
    "        'z': SNRdb[:, 2].reshape(original_shape)\n",
    "    }\n",
    "    R = {\n",
    "        'x': rho2_ETC[:, 0].reshape(original_shape),\n",
    "        'y': rho2_ETC[:, 1].reshape(original_shape),\n",
    "        'z': rho2_ETC[:, 2].reshape(original_shape)\n",
    "    }\n",
    "    fMSE = {\n",
    "        'x': (1 - rho2_ETC[:, 0]).reshape(original_shape),\n",
    "        'y': (1 - rho2_ETC[:, 1]).reshape(original_shape),\n",
    "        'z': (1 - rho2_ETC[:, 2]).reshape(original_shape)\n",
    "    }\n",
    "\n",
    "    # 3. Set the flags\n",
    "    condition_corr = ((R['x'] < corr_th) | (R['y'] < corr_th) | (R['z'] < corr_th)).reshape(original_shape)\n",
    "    condition_n_valid = np.sum(~np.isnan(X) & ~np.isnan(Y) & ~np.isnan(Z), axis=-1) < nod_th\n",
    "    condition_fMSE = ((fMSE['x'] < 0) | (fMSE['y'] < 0) | (fMSE['z'] < 0) | \n",
    "                      (fMSE['x'] > 1) | (fMSE['y'] > 1) | (fMSE['z'] > 1)).reshape(original_shape)\n",
    "    condition_negative_vars_err = (errVar_ETC < 0).any(axis=1).reshape(original_shape)\n",
    "\n",
    "    flags = {\n",
    "        'condition_corr': condition_corr,\n",
    "        'condition_n_valid': condition_n_valid,\n",
    "        'condition_fMSE': condition_fMSE,\n",
    "        'condition_negative_vars_err': condition_negative_vars_err\n",
    "    }\n",
    "\n",
    "    return VAR_err, SNR, SNRdb, R, fMSE, flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETC(D1, D2, D3, nod_th=30, corr_th=0):\n",
    "    \"\"\"\n",
    "    Extended Triple Collocation (ETC) is a technique for estimating the\n",
    "    variance of the noise error (errVar) and correlation coefficients (rho)\n",
    "    of three measurement systems (e.g., satellite, in-situ, and model-based products)\n",
    "    with respect to the unknown true value of the variable being measured\n",
    "    (e.g., soil moisture, wind speed).\n",
    "\n",
    "    INPUTS\n",
    "    D1, D2, D3: Arrays of observations from the three measurement systems.\n",
    "    They must be of the same length, and all NaNs must be removed or handled appropriately.\n",
    "\n",
    "    OUTPUTS\n",
    "    errVar_ETC: A list of error variances [errVar_D1, errVar_D2, errVar_D3].\n",
    "    rho2_ETC: A list of squared correlation coefficients [rho2_D1, rho2_D2, rho2_D3].\n",
    "\n",
    "    REFERENCE\n",
    "    McColl, K.A., J. Vogelzang, A.G. Konings, D. Entekhabi, M. Piles, A. Stoffelen (2014).\n",
    "    Extended Triple Collocation: Estimating errors and correlation coefficients with respect\n",
    "    to an unknown target. Geophysical Research Letters 41:6229-6236.\n",
    "    \"\"\"\n",
    "    # Convert inputs to numpy arrays\n",
    "    D1 = np.asarray(D1)\n",
    "    D2 = np.asarray(D2)\n",
    "    D3 = np.asarray(D3)\n",
    "\n",
    "    # Check that all inputs have the same length\n",
    "    if not (len(D1) == len(D2) == len(D3)):\n",
    "        raise ValueError('Error: Input data D1, D2, D3 must be of the same length.')\n",
    "\n",
    "    # Combine the data into a single array\n",
    "    y = np.column_stack((D1, D2, D3))  # Shape: (N, 3)\n",
    "\n",
    "    # Remove any rows with NaNs\n",
    "    if np.isnan(y).any():\n",
    "        y = y[~np.isnan(y).any(axis=1)]\n",
    "\n",
    "    # Catch errors in inputs\n",
    "    if y.shape[1] != 3:\n",
    "        raise ValueError('Error: Input data must result in an N x 3 array after removing NaNs.')\n",
    "\n",
    "    if y.size == 0:\n",
    "        raise ValueError('Error: No data left after removing NaNs.')\n",
    "\n",
    "    # Check that each column has non-zero variance\n",
    "    if np.var(y[:, 0]) == 0 or np.var(y[:, 1]) == 0 or np.var(y[:, 2]) == 0:\n",
    "        raise ValueError('Error: The sample variance of each dataset must be non-zero.')\n",
    "\n",
    "    # Estimate covariance matrix of the three measurement systems\n",
    "    Q_hat = np.cov(y, rowvar=False)\n",
    "\n",
    "    # Compute correlation coefficients\n",
    "    rho_ETC = np.zeros(3)\n",
    "\n",
    "    try:\n",
    "        rho_ETC[0] = np.sqrt(Q_hat[0, 1] * Q_hat[0, 2] / (Q_hat[0, 0] * Q_hat[1, 2]))\n",
    "        rho_ETC[1] = np.sign(Q_hat[0, 2] * Q_hat[1, 2]) * np.sqrt(Q_hat[0, 1] * Q_hat[1, 2] / (Q_hat[1, 1] * Q_hat[0, 2]))\n",
    "        rho_ETC[2] = np.sign(Q_hat[0, 1] * Q_hat[1, 2]) * np.sqrt(Q_hat[0, 2] * Q_hat[1, 2] / (Q_hat[2, 2] * Q_hat[0, 1]))\n",
    "    except (ZeroDivisionError, FloatingPointError, ValueError):\n",
    "        raise ValueError('Error: Calculation of correlation coefficients failed due to invalid covariance values.')\n",
    "\n",
    "    rho2_ETC = rho_ETC ** 2\n",
    "\n",
    "    # Compute error variances\n",
    "    errVar_ETC = np.zeros(3)\n",
    "    errVar_ETC[0] = Q_hat[0, 0] - (Q_hat[0, 1] * Q_hat[0, 2]) / Q_hat[1, 2]\n",
    "    errVar_ETC[1] = Q_hat[1, 1] - (Q_hat[0, 1] * Q_hat[1, 2]) / Q_hat[0, 2]\n",
    "    errVar_ETC[2] = Q_hat[2, 2] - (Q_hat[0, 2] * Q_hat[1, 2]) / Q_hat[0, 1]\n",
    "\n",
    "    # Check for negative error variances\n",
    "    if np.any(errVar_ETC < 0):\n",
    "        print('Warning: At least one calculated errVar is negative. This can happen if the sample size is too small or if one of the assumptions of ETC is violated.')\n",
    "\n",
    "    # Check for negative squared correlation coefficients\n",
    "    if np.any(rho2_ETC < 0):\n",
    "        print('Warning: At least one calculated squared correlation coefficient is negative. This can happen if the sample size is too small or if one of the assumptions of ETC is violated.')\n",
    "\n",
    "    # ======================================================\n",
    "    # Computer SNR\n",
    "    SNR = np.zeros(3)\n",
    "    SNRdb = np.zeros(3)\n",
    "\n",
    "    SNR[0] = (rho2_ETC[0]) / (1 - rho2_ETC[0])\n",
    "    SNRdb[0] = 10 * np.log10(SNR[0])\n",
    "    SNR[1] = (rho2_ETC[1]) / (1 - rho2_ETC[1])\n",
    "    SNRdb[1] = 10 * np.log10(SNR[1])\n",
    "    SNR[2] = (rho2_ETC[2]) / (1 - rho2_ETC[2])\n",
    "    SNRdb[2] = 10 * np.log10(SNR[2])\n",
    "\n",
    "    # Prepare outputs\n",
    "    VAR_err = {\n",
    "        'x': errVar_ETC[0],\n",
    "        'y': errVar_ETC[1],\n",
    "        'z': errVar_ETC[2]\n",
    "    }\n",
    "    SNR = {\n",
    "        'x': SNR[0],\n",
    "        'y': SNR[1],\n",
    "        'z': SNR[2]\n",
    "    }\n",
    "    SNRdb = {\n",
    "        'x': SNRdb[0],\n",
    "        'y': SNRdb[1],\n",
    "        'z': SNRdb[2]\n",
    "    }\n",
    "    R = {\n",
    "        'x': rho2_ETC[0],\n",
    "        'y': rho2_ETC[1],\n",
    "        'z': rho2_ETC[2]\n",
    "    }\n",
    "    fMSE = {\n",
    "        'x': 1 - rho2_ETC[0],\n",
    "        'y': 1 - rho2_ETC[1],\n",
    "        'z': 1 - rho2_ETC[2]\n",
    "    }\n",
    "    # Set the flags\n",
    "    # Flag on non-scaled data (not necessary here as we didn't calculate corrXY)\n",
    "    # flags on correlation coefficients\n",
    "    condition_corr = (R['x'] < corr_th) | (R['y'] < corr_th) | (R['z'] < corr_th)  # flag 1\n",
    "    # flag on valid number of observations\n",
    "    condition_n_valid = np.sum(~np.isnan(D1) & ~np.isnan(D2) & ~np.isnan(D3), axis=0) < nod_th # flag 2 (axis=0 is due to 1D array\n",
    "    # flags on fMSE\n",
    "    condition_fMSE = (fMSE['x'] < 0) | (fMSE['y'] < 0) | (fMSE['z'] < 0) | (fMSE['x'] > 1) | (fMSE['y'] > 1) | (fMSE['z'] > 1)  # flag 3\n",
    "    # flag on negative error variances\n",
    "    condition_negative_vars_err = (errVar_ETC < 0).any(axis=0)  # flag 4 (axis=0 is due to 1D array)\n",
    "\n",
    "    flags = {'condition_corr': condition_corr,\n",
    "            'condition_n_valid': condition_n_valid,\n",
    "            'condition_fMSE': condition_fMSE,\n",
    "            'condition_negative_vars_err': condition_negative_vars_err}\n",
    "\n",
    "    return VAR_err, SNR, SNRdb, R, fMSE, flags"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check values by switching X and Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)  # For reproducibility\n",
    "\n",
    "N = 1000  # Number of data points\n",
    "\n",
    "# Generate the true signal T\n",
    "T = np.random.normal(0, 1, 4*N)  # Mean 0, standard deviation 1\n",
    "\n",
    "# Generate errors for each dataset\n",
    "e1 = np.random.normal(0, 0.5, 4*N)  # Error variance 0.25\n",
    "e2 = np.random.normal(0, 0.7, 4*N)  # Error variance 0.49\n",
    "e3 = np.random.normal(0, 0.9, 4*N)  # Error variance 0.81\n",
    "\n",
    "# Generate the datasets\n",
    "D1 = T + e1\n",
    "D2 = T + e2\n",
    "D3 = T + e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to 3D arrays with shape (1, 1, N)\n",
    "X = D1.reshape(2, 2, N)\n",
    "Y = D2.reshape(2, 2, N)\n",
    "Z = D3.reshape(2, 2, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. Old version (scaled)\n",
      " [[0.26481391 0.18906668]\n",
      " [0.28502206 0.26616256]]\n",
      "\n",
      "2. Old version (scaled)\n",
      " [[0.44447355 0.62894485]\n",
      " [0.49474468 0.47151674]]\n",
      "\n",
      "3. Old version (scaled)\n",
      " [[0.8314466  0.8088448 ]\n",
      " [0.74024721 0.77950874]]\n",
      "\n",
      "1. Old version (scaled, switched X and Y)\n",
      " [[0.46120713 0.53868863]\n",
      " [0.46783316 0.47956407]]\n",
      "\n",
      "2. Old version (scaled, switched X and Y)\n",
      " [[0.27478365 0.16193482]\n",
      " [0.26951835 0.27070513]]\n",
      "\n",
      "3. Old version (scaled, switched X and Y)\n",
      " [[0.86274897 0.69277219]\n",
      " [0.69998163 0.79281253]]\n"
     ]
    }
   ],
   "source": [
    "# Previous TCA_vec_old code\n",
    "VAR_err_TCA_old, SNR_TCA_old, SNRdb_TCA_old, R_TCA_old, fMSE_TCA_old, flags_TCA_old = hTCL.TCA_vec_old(X, Y, Z)\n",
    "print('\\n1. Old version (scaled)\\n', VAR_err_TCA_old['x'])\n",
    "print('\\n2. Old version (scaled)\\n', VAR_err_TCA_old['y'])\n",
    "print('\\n3. Old version (scaled)\\n', VAR_err_TCA_old['z'])\n",
    "\n",
    "VAR_err_TCA_old, SNR_TCA_old, SNRdb_TCA_old, R_TCA_old, fMSE_TCA_old, flags_TCA_old = hTCL.TCA_vec_old(Y, X, Z)\n",
    "print('\\n1. Old version (scaled, switched X and Y)\\n', VAR_err_TCA_old['x'])\n",
    "print('\\n2. Old version (scaled, switched X and Y)\\n', VAR_err_TCA_old['y'])\n",
    "print('\\n3. Old version (scaled, switched X and Y)\\n', VAR_err_TCA_old['z'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This function is renamed as ETC_vec\n",
      "\n",
      "1.Old version (unscaled)\n",
      " [[0.26481391 0.18906668]\n",
      " [0.28502206 0.26616256]]\n",
      "\n",
      "2. Old version (unscaled)\n",
      " [[0.46120713 0.53868863]\n",
      " [0.46783316 0.47956407]]\n",
      "\n",
      "3.Old version (unscaled)\n",
      " [[0.8428336  0.77998994]\n",
      " [0.74911562 0.81002849]]\n",
      "\n",
      "1. Old version (unscaled, switched X and Y)\n",
      " [[0.46120713 0.53868863]\n",
      " [0.46783316 0.47956407]]\n",
      "\n",
      "2. Old version (unscaled, switched X and Y)\n",
      " [[0.26481391 0.18906668]\n",
      " [0.28502206 0.26616256]]\n",
      "\n",
      "3. Old version (unscaled, switched X and Y)\n",
      " [[0.8428336  0.77998994]\n",
      " [0.74911562 0.81002849]]\n"
     ]
    }
   ],
   "source": [
    "print('This function is renamed as ETC_vec')\n",
    "VAR_err_TCA_old, SNR_TCA_old, SNRdb_TCA_old, R_TCA_old, fMSE_TCA_old, flags_TCA_old = hTCL.ETC_vec(X, Y, Z)\n",
    "print('\\n1.Old version (unscaled)\\n', VAR_err_TCA_old['x'])\n",
    "print('\\n2. Old version (unscaled)\\n', VAR_err_TCA_old['y'])\n",
    "print('\\n3.Old version (unscaled)\\n', VAR_err_TCA_old['z'])\n",
    "\n",
    "VAR_err_TCA_old, SNR_TCA_old, SNRdb_TCA_old, R_TCA_old, fMSE_TCA_old, flags_TCA_old = hTCL.ETC_vec(Y, X, Z)\n",
    "print('\\n1. Old version (unscaled, switched X and Y)\\n', VAR_err_TCA_old['x'])\n",
    "print('\\n2. Old version (unscaled, switched X and Y)\\n', VAR_err_TCA_old['y'])\n",
    "print('\\n3. Old version (unscaled, switched X and Y)\\n', VAR_err_TCA_old['z'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. New version\n",
      " [[0.26481391 0.18906668]\n",
      " [0.28502206 0.26616256]]\n",
      "\n",
      "2. New version\n",
      " [[0.46120713 0.53868863]\n",
      " [0.46783316 0.47956407]]\n",
      "\n",
      "3. New version\n",
      " [[0.8428336  0.77998994]\n",
      " [0.74911562 0.81002849]]\n",
      "\n",
      "1. New version (Switched X and Y)\n",
      " [[0.46120713 0.53868863]\n",
      " [0.46783316 0.47956407]]\n",
      "\n",
      "2. New version (Switched X and Y)\n",
      " [[0.26481391 0.18906668]\n",
      " [0.28502206 0.26616256]]\n",
      "\n",
      "3. New version (Switched X and Y)\n",
      " [[0.8428336  0.77998994]\n",
      " [0.74911562 0.81002849]]\n"
     ]
    }
   ],
   "source": [
    "# Assume TCA_vec is already defined as per the modified code\n",
    "VAR_err_TCA, SNR_TCA, SNRdb_TCA, R_TCA, fMSE_TCA, flags_TCA = hTCL.TCA_vec(X, Y, Z)\n",
    "print('\\n1. New version\\n', VAR_err_TCA['x'])\n",
    "print('\\n2. New version\\n', VAR_err_TCA['y'])\n",
    "print('\\n3. New version\\n', VAR_err_TCA['z'])\n",
    "\n",
    "# Assume TCA_vec is already defined as per the modified code\n",
    "VAR_err_TCA2, SNR_TCA2, SNRdb_TCA2, R_TCA2, fMSE_TCA2, flags_TCA2 = hTCL.TCA_vec(Y, X, Z)\n",
    "print('\\n1. New version (Switched X and Y)\\n', VAR_err_TCA2['x'])\n",
    "print('\\n2. New version (Switched X and Y)\\n', VAR_err_TCA2['y'])\n",
    "print('\\n3. New version (Switched X and Y)\\n', VAR_err_TCA2['z'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ETC\n",
      " 0.2522540373117278\n",
      "\n",
      "ETC\n",
      " 0.48744442691353373\n",
      "\n",
      "ETC\n",
      " 0.794874726108981\n",
      "\n",
      "ETC (Switched D1 and D2)\n",
      " 0.48744442691353373\n",
      "\n",
      "ETC (Switched D1 and D2)\n",
      " 0.2522540373117278\n",
      "\n",
      "ETC (Switched D1 and D2)\n",
      " 0.794874726108981\n"
     ]
    }
   ],
   "source": [
    "errVar_ETC, SNR_ETC, SNRdb_ETC, R_ETC, fMSE_ETC, flags_ETC = hTCL.ETC(D1, D2, D3)\n",
    "print('\\nETC\\n', errVar_ETC['x'])\n",
    "print('\\nETC\\n', errVar_ETC['y'])\n",
    "print('\\nETC\\n', errVar_ETC['z'])\n",
    "#print(D1[:10])\n",
    "#print(D2[:10])\n",
    "\n",
    "errVar_ETC, SNR_ETC, SNRdb_ETC, R_ETC, fMSE_ETC, flags_ETC = hTCL.ETC(D2, D1, D3)\n",
    "print('\\nETC (Switched D1 and D2)\\n', errVar_ETC['x'])\n",
    "print('\\nETC (Switched D1 and D2)\\n', errVar_ETC['y'])\n",
    "print('\\nETC (Switched D1 and D2)\\n', errVar_ETC['z'])\n",
    "\n",
    "#print(D1[:10])\n",
    "#print(D2[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. ETC\n",
      " [[0.26481391 0.18906668]\n",
      " [0.28502206 0.26616256]]\n",
      "\n",
      "2. ETC\n",
      " [[0.46120713 0.53868863]\n",
      " [0.46783316 0.47956407]]\n",
      "\n",
      "3. ETC\n",
      " [[0.8428336  0.77998994]\n",
      " [0.74911562 0.81002849]]\n",
      "\n",
      "1. ETC (Switched X and Y)\n",
      " [[0.46120713 0.53868863]\n",
      " [0.46783316 0.47956407]]\n",
      "\n",
      "2. ETC (Switched X and Y)\n",
      " [[0.26481391 0.18906668]\n",
      " [0.28502206 0.26616256]]\n",
      "\n",
      "3. ETC (Switched X and Y)\n",
      " [[0.8428336  0.77998994]\n",
      " [0.74911562 0.81002849]]\n"
     ]
    }
   ],
   "source": [
    "ETC_total_x = []\n",
    "ETC_total_y = []\n",
    "ETC_total_z = []\n",
    "# Assume ETC is already defined as per the provided code\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        errVar_ETC, SNR_ETC, SNRdb_ETC, R_ETC, fMSE_ETC, flags_ETC = hTCL.ETC(X[i, j, :], Y[i, j, :], Z[i, j, :])\n",
    "        ETC_total_x.append(errVar_ETC['x'])\n",
    "        ETC_total_y.append(errVar_ETC['y'])\n",
    "        ETC_total_z.append(errVar_ETC['z'])\n",
    "\n",
    "print('\\n1. ETC\\n', np.array(ETC_total_x).reshape(2,2))\n",
    "print('\\n2. ETC\\n', np.array(ETC_total_y).reshape(2,2))\n",
    "print('\\n3. ETC\\n', np.array(ETC_total_z).reshape(2,2))\n",
    "\n",
    "# Switch test\n",
    "ETC_total_x = []\n",
    "ETC_total_y = []\n",
    "ETC_total_z = []\n",
    "# Assume ETC is already defined as per the provided code\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        errVar_ETC, SNR_ETC, SNRdb_ETC, R_ETC, fMSE_ETC, flags_ETC = hTCL.ETC(Y[i, j, :], X[i, j, :], Z[i, j, :])\n",
    "        ETC_total_x.append(errVar_ETC['x'])\n",
    "        ETC_total_y.append(errVar_ETC['y'])\n",
    "        ETC_total_z.append(errVar_ETC['z'])\n",
    "\n",
    "print('\\n1. ETC (Switched X and Y)\\n', np.array(ETC_total_x).reshape(2,2))      \n",
    "print('\\n2. ETC (Switched X and Y)\\n', np.array(ETC_total_y).reshape(2,2))\n",
    "print('\\n3. ETC (Switched X and Y)\\n', np.array(ETC_total_z).reshape(2,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average execution time for ETC_vec: 0.000560 seconds\n",
      "Average execution time for TCA_vec: 0.000548 seconds\n",
      "Average execution time for ETC: 0.000575 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# Assuming you have already defined TCA_vec_old, TCA_vec, and ETC functions\n",
    "# and have your input data X, Y, Z, D1, D2, D3 ready\n",
    "\n",
    "def time_function(func, *args):\n",
    "    start_time = time.time()\n",
    "    result = func(*args)\n",
    "    end_time = time.time()\n",
    "    return end_time - start_time, result\n",
    "\n",
    "# Number of iterations for more accurate timing\n",
    "n_iterations = 100\n",
    "\n",
    "# Time TCA_vec_old\n",
    "total_time_old = 0\n",
    "for _ in range(n_iterations):\n",
    "    execution_time, _ = time_function(ETC_vec, X, Y, Z)\n",
    "    total_time_old += execution_time\n",
    "avg_time_old = total_time_old / n_iterations\n",
    "\n",
    "# Time TCA_vec\n",
    "total_time_new = 0\n",
    "for _ in range(n_iterations):\n",
    "    execution_time, _ = time_function(TCA_vec, X, Y, Z)\n",
    "    total_time_new += execution_time\n",
    "avg_time_new = total_time_new / n_iterations\n",
    "\n",
    "# Time ETC\n",
    "total_time_etc = 0\n",
    "for _ in range(n_iterations):\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            execution_time, _ = time_function(ETC, X[i, j, :], Y[i, j, :], Z[i, j, :])\n",
    "            total_time_etc += execution_time\n",
    "avg_time_etc = total_time_etc / n_iterations\n",
    "\n",
    "print(f\"Average execution time for ETC_vec: {avg_time_old:.6f} seconds\")\n",
    "print(f\"Average execution time for TCA_vec: {avg_time_new:.6f} seconds\")\n",
    "print(f\"Average execution time for ETC: {avg_time_etc:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.07072693  1.3220072   1.11428348  2.80911701  0.99839206 -0.62371051\n",
      "  0.96528148         nan  0.33061376 -0.71752656]\n",
      "[ 2.46254368  0.58221372  1.62628391  3.2741463   0.55208139 -1.52504786\n",
      " -0.03145512         nan -0.90985364  0.47818249]\n",
      "[ 2.6150099   0.7807884  -0.07937401  2.05652701  2.72840393  0.45024271\n",
      "  1.66224402         nan -0.70772905 -0.21654611]\n"
     ]
    }
   ],
   "source": [
    "def generate_test_data_with_nans(N, nan_percentage=0.1):\n",
    "    \"\"\"\n",
    "    Generate test datasets with NaN values.\n",
    "    \n",
    "    Args:\n",
    "    N (int): Number of data points\n",
    "    nan_percentage (float): Percentage of NaN values to include (0 to 1)\n",
    "    \n",
    "    Returns:\n",
    "    X, Y, Z (np.array): 3D arrays with shape (2, 2, N) containing the test data\n",
    "    \"\"\"\n",
    "    np.random.seed(0)  # For reproducibility\n",
    "\n",
    "    # Generate the true signal T\n",
    "    T = np.random.normal(0, 1, 4*N)  # Mean 0, standard deviation 1\n",
    "\n",
    "    # Generate errors for each dataset\n",
    "    e1 = np.random.normal(0, 0.5, 4*N)  # Error variance 0.25\n",
    "    e2 = np.random.normal(0, 0.7, 4*N)  # Error variance 0.49\n",
    "    e3 = np.random.normal(0, 0.9, 4*N)  # Error variance 0.81\n",
    "\n",
    "    # Generate the datasets\n",
    "    D1 = T + e1\n",
    "    D2 = T + e2\n",
    "    D3 = T + e3\n",
    "\n",
    "    # Reshape data to 3D arrays with shape (2, 2, N)\n",
    "    X = D1.reshape(2, 2, N)\n",
    "    Y = D2.reshape(2, 2, N)\n",
    "    Z = D3.reshape(2, 2, N)\n",
    "\n",
    "    # Add NaN values\n",
    "    nan_mask = np.random.random(X.shape) < nan_percentage\n",
    "    X[nan_mask] = np.nan\n",
    "    Y[nan_mask] = np.nan\n",
    "    Z[nan_mask] = np.nan\n",
    "\n",
    "    return X, Y, Z\n",
    "\n",
    "# Generate new test data with NaN values\n",
    "N = 1000\n",
    "X_nan, Y_nan, Z_nan = generate_test_data_with_nans(N, nan_percentage=0.1)\n",
    "print(X_nan[0,0,:10])\n",
    "print(Y_nan[0,0,:10])\n",
    "print(Z_nan[0,0,:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average execution time for ETC_vec: 0.000634 seconds\n",
      "Average execution time for TCA_vec: 0.000553 seconds\n",
      "Average execution time for ETC: 0.000688 seconds\n"
     ]
    }
   ],
   "source": [
    "# Number of iterations for more accurate timing\n",
    "n_iterations = 100\n",
    "\n",
    "# Time TCA_vec_old\n",
    "total_time_old = 0\n",
    "for _ in range(n_iterations):\n",
    "    execution_time, _ = time_function(ETC_vec, X_nan, Y_nan, Z_nan)\n",
    "    total_time_old += execution_time\n",
    "avg_time_old = total_time_old / n_iterations\n",
    "\n",
    "# Time TCA_vec\n",
    "total_time_new = 0\n",
    "for _ in range(n_iterations):\n",
    "    execution_time, _ = time_function(TCA_vec, X_nan, Y_nan, Z_nan)\n",
    "    total_time_new += execution_time\n",
    "avg_time_new = total_time_new / n_iterations\n",
    "\n",
    "# Time ETC\n",
    "total_time_etc = 0\n",
    "for _ in range(n_iterations):\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            execution_time, _ = time_function(ETC, X_nan[i, j, :], Y_nan[i, j, :], Z_nan[i, j, :])\n",
    "            total_time_etc += execution_time\n",
    "avg_time_etc = total_time_etc / n_iterations\n",
    "\n",
    "print(f\"Average execution time for ETC_vec: {avg_time_old:.6f} seconds\")\n",
    "print(f\"Average execution time for TCA_vec: {avg_time_new:.6f} seconds\")\n",
    "print(f\"Average execution time for ETC: {avg_time_etc:.6f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydroai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
