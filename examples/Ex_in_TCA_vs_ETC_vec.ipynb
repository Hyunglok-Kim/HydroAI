{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import platform\n",
    "import sys\n",
    "import datetime\n",
    "import netCDF4\n",
    "import numpy as np\n",
    "import importlib\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "base_FP = '/home/subin/data'\n",
    "cpuserver_data_FP = '/home/subin/cpuserver_data'\n",
    "sys.path.append(base_FP + '/python_modules')\n",
    "\n",
    "import develop_HydroAI.HydroAI.TC_like as hTCL\n",
    "import develop_HydroAI.HydroAI.Vectorization as hVec\n",
    "import matplotlib.pyplot as plt\n",
    "importlib.reload(hTCL);\n",
    "importlib.reload(hVec);\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# Define your directory where to save nc files\n",
    "nc_save_dir = cpuserver_data_FP + '/extracted_nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def TCA_vec(X, Y, Z, nod_th=30, corr_th=0):\n",
    "    # 0. Check for NaNs and ensure that any NaNs are consistent across datasets\n",
    "    combined_nan_mask = np.isnan(X) | np.isnan(Y) | np.isnan(Z)\n",
    "    X[combined_nan_mask] = np.nan\n",
    "    Y[combined_nan_mask] = np.nan\n",
    "    Z[combined_nan_mask] = np.nan\n",
    "\n",
    "    # Remove completely NaN slices (if data is 3D)\n",
    "    valid_mask = ~np.isnan(X).all(axis=2) & ~np.isnan(Y).all(axis=2) & ~np.isnan(Z).all(axis=2)\n",
    "    X = X[valid_mask]\n",
    "    Y = Y[valid_mask]\n",
    "    Z = Z[valid_mask]\n",
    "\n",
    "    # 1. Flatten the data to 2D arrays if necessary\n",
    "    X_flat = X.reshape(-1, X.shape[-1])\n",
    "    Y_flat = Y.reshape(-1, Y.shape[-1])\n",
    "    Z_flat = Z.reshape(-1, Z.shape[-1])\n",
    "\n",
    "    # Remove rows with NaNs\n",
    "    valid_rows = ~np.isnan(X_flat).any(axis=1) & ~np.isnan(Y_flat).any(axis=1) & ~np.isnan(Z_flat).any(axis=1)\n",
    "    X_flat = X_flat[valid_rows]\n",
    "    Y_flat = Y_flat[valid_rows]\n",
    "    Z_flat = Z_flat[valid_rows]\n",
    "\n",
    "    # Combine the data into a single array\n",
    "    data = np.stack((X_flat, Y_flat, Z_flat), axis=1)  # Shape: (N, 3, T)\n",
    "\n",
    "    # Initialize arrays to store results\n",
    "    N = data.shape[0]\n",
    "    errVar_ETC = np.zeros((N, 3))\n",
    "    rho2_ETC = np.zeros((N, 3))\n",
    "    SNR = np.zeros((N, 3))\n",
    "    SNRdb = np.zeros((N, 3))\n",
    "\n",
    "    # Iterate over each time series (row)\n",
    "    for i in range(N):\n",
    "        y = data[i, :, :].T  # Shape: (T, 3)\n",
    "\n",
    "        # Check that there are enough valid observations\n",
    "        if y.shape[0] < nod_th:\n",
    "            continue  # Skip if not enough data\n",
    "\n",
    "        # Remove any remaining NaNs\n",
    "        if np.isnan(y).any():\n",
    "            continue  # Skip if there are NaNs\n",
    "\n",
    "        # Compute covariance matrix\n",
    "        Q_hat = np.cov(y, rowvar=False)\n",
    "\n",
    "        # Ensure covariance matrix is full rank\n",
    "        if np.linalg.matrix_rank(Q_hat) < 3:\n",
    "            continue  # Skip if covariance matrix is singular\n",
    "\n",
    "        # Calculate correlation coefficients\n",
    "        try:\n",
    "            rho_ETC = np.zeros(3)\n",
    "            rho_ETC[0] = np.sqrt(Q_hat[0,1]*Q_hat[0,2]/(Q_hat[0,0]*Q_hat[1,2]))\n",
    "            rho_ETC[1] = np.sign(Q_hat[0,2]*Q_hat[1,2]) * np.sqrt(Q_hat[0,1]*Q_hat[1,2]/(Q_hat[1,1]*Q_hat[0,2]))\n",
    "            rho_ETC[2] = np.sign(Q_hat[0,1]*Q_hat[1,2]) * np.sqrt(Q_hat[0,2]*Q_hat[1,2]/(Q_hat[2,2]*Q_hat[0,1]))\n",
    "\n",
    "            rho2_ETC[i, :] = rho_ETC**2\n",
    "\n",
    "            # Calculate error variances\n",
    "            errVar_ETC[i, 0] = Q_hat[0,0] - Q_hat[0,1]*Q_hat[0,2]/Q_hat[1,2]\n",
    "            errVar_ETC[i, 1] = Q_hat[1,1] - Q_hat[0,1]*Q_hat[1,2]/Q_hat[0,2]\n",
    "            errVar_ETC[i, 2] = Q_hat[2,2] - Q_hat[0,2]*Q_hat[1,2]/Q_hat[0,1]\n",
    "\n",
    "            # Calculate SNR\n",
    "            SNR[i, :] = (rho2_ETC[i, :]) / (1 - rho2_ETC[i, :])\n",
    "\n",
    "            # Calculate SNR in dB\n",
    "            SNRdb[i, :] = 10 * np.log10(SNR[i, :])\n",
    "\n",
    "        except Exception as e:\n",
    "            # Handle any mathematical errors (e.g., division by zero)\n",
    "            continue\n",
    "\n",
    "    # Prepare outputs\n",
    "    VAR_err = {\n",
    "        'x': errVar_ETC[:, 0],\n",
    "        'y': errVar_ETC[:, 1],\n",
    "        'z': errVar_ETC[:, 2]\n",
    "    }\n",
    "    SNR = {\n",
    "        'x': SNR[:, 0],\n",
    "        'y': SNR[:, 1],\n",
    "        'z': SNR[:, 2]\n",
    "    }\n",
    "    SNRdb = {\n",
    "        'x': SNRdb[:, 0],\n",
    "        'y': SNRdb[:, 1],\n",
    "        'z': SNRdb[:, 2]\n",
    "    }\n",
    "    R = {\n",
    "        'x': rho2_ETC[:, 0],\n",
    "        'y': rho2_ETC[:, 1],\n",
    "        'z': rho2_ETC[:, 2]\n",
    "    }\n",
    "    fMSE = {\n",
    "        'x': 1 - rho2_ETC[:, 0],\n",
    "        'y': 1 - rho2_ETC[:, 1],\n",
    "        'z': 1 - rho2_ETC[:, 2]\n",
    "    }\n",
    "\n",
    "    # 3. Set the flags\n",
    "    # Flag on non-scaled data (not necessary here as we didn't calculate corrXY)\n",
    "    # flags on correlation coefficients\n",
    "    condition_corr = (R['x'] < corr_th) | (R['y'] < corr_th) | (R['z'] < corr_th)  # flag 1\n",
    "    # flag on valid number of observations\n",
    "    condition_n_valid = np.sum(~np.isnan(X_flat) & ~np.isnan(Y_flat) & ~np.isnan(Z_flat), axis=1) < nod_th\n",
    "    # flags on fMSE\n",
    "    condition_fMSE = (fMSE['x'] < 0) | (fMSE['y'] < 0) | (fMSE['z'] < 0) | (fMSE['x'] > 1) | (fMSE['y'] > 1) | (fMSE['z'] > 1)  # flag 3\n",
    "    # flag on negative error variances\n",
    "    condition_negative_vars_err = (errVar_ETC < 0).any(axis=1)  # flag 4\n",
    "\n",
    "    flags = {'condition_corr': condition_corr,\n",
    "            'condition_n_valid': condition_n_valid,\n",
    "            'condition_fMSE': condition_fMSE,\n",
    "            'condition_negative_vars_err': condition_negative_vars_err}\n",
    "\n",
    "    return VAR_err, SNR, SNRdb, R, fMSE, flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ETC(D1, D2, D3, nod_th=30, corr_th=0):\n",
    "    \"\"\"\n",
    "    Extended Triple Collocation (ETC) is a technique for estimating the\n",
    "    variance of the noise error (errVar) and correlation coefficients (rho)\n",
    "    of three measurement systems (e.g., satellite, in-situ, and model-based products)\n",
    "    with respect to the unknown true value of the variable being measured\n",
    "    (e.g., soil moisture, wind speed).\n",
    "\n",
    "    INPUTS\n",
    "    D1, D2, D3: Arrays of observations from the three measurement systems.\n",
    "    They must be of the same length, and all NaNs must be removed or handled appropriately.\n",
    "\n",
    "    OUTPUTS\n",
    "    errVar_ETC: A list of error variances [errVar_D1, errVar_D2, errVar_D3].\n",
    "    rho2_ETC: A list of squared correlation coefficients [rho2_D1, rho2_D2, rho2_D3].\n",
    "\n",
    "    REFERENCE\n",
    "    McColl, K.A., J. Vogelzang, A.G. Konings, D. Entekhabi, M. Piles, A. Stoffelen (2014).\n",
    "    Extended Triple Collocation: Estimating errors and correlation coefficients with respect\n",
    "    to an unknown target. Geophysical Research Letters 41:6229-6236.\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert inputs to numpy arrays\n",
    "    D1 = np.asarray(D1)\n",
    "    D2 = np.asarray(D2)\n",
    "    D3 = np.asarray(D3)\n",
    "\n",
    "    # Check that all inputs have the same length\n",
    "    if not (len(D1) == len(D2) == len(D3)):\n",
    "        raise ValueError('Error: Input data D1, D2, D3 must be of the same length.')\n",
    "\n",
    "    # Combine the data into a single array\n",
    "    y = np.column_stack((D1, D2, D3))  # Shape: (N, 3)\n",
    "\n",
    "    # Remove any rows with NaNs\n",
    "    if np.isnan(y).any():\n",
    "        y = y[~np.isnan(y).any(axis=1)]\n",
    "\n",
    "    # Catch errors in inputs\n",
    "    if y.shape[1] != 3:\n",
    "        raise ValueError('Error: Input data must result in an N x 3 array after removing NaNs.')\n",
    "\n",
    "    if y.size == 0:\n",
    "        raise ValueError('Error: No data left after removing NaNs.')\n",
    "\n",
    "    # Check that each column has non-zero variance\n",
    "    if np.var(y[:, 0]) == 0 or np.var(y[:, 1]) == 0 or np.var(y[:, 2]) == 0:\n",
    "        raise ValueError('Error: The sample variance of each dataset must be non-zero.')\n",
    "\n",
    "    # Estimate covariance matrix of the three measurement systems\n",
    "    Q_hat = np.cov(y, rowvar=False)\n",
    "\n",
    "    # Compute correlation coefficients\n",
    "    rho_ETC = np.zeros(3)\n",
    "\n",
    "    try:\n",
    "        rho_ETC[0] = np.sqrt(Q_hat[0, 1] * Q_hat[0, 2] / (Q_hat[0, 0] * Q_hat[1, 2]))\n",
    "        rho_ETC[1] = np.sign(Q_hat[0, 2] * Q_hat[1, 2]) * np.sqrt(Q_hat[0, 1] * Q_hat[1, 2] / (Q_hat[1, 1] * Q_hat[0, 2]))\n",
    "        rho_ETC[2] = np.sign(Q_hat[0, 1] * Q_hat[1, 2]) * np.sqrt(Q_hat[0, 2] * Q_hat[1, 2] / (Q_hat[2, 2] * Q_hat[0, 1]))\n",
    "    except (ZeroDivisionError, FloatingPointError, ValueError):\n",
    "        raise ValueError('Error: Calculation of correlation coefficients failed due to invalid covariance values.')\n",
    "\n",
    "    rho2_ETC = rho_ETC ** 2\n",
    "\n",
    "    # Compute error variances\n",
    "    errVar_ETC = np.zeros(3)\n",
    "    errVar_ETC[0] = Q_hat[0, 0] - (Q_hat[0, 1] * Q_hat[0, 2]) / Q_hat[1, 2]\n",
    "    errVar_ETC[1] = Q_hat[1, 1] - (Q_hat[0, 1] * Q_hat[1, 2]) / Q_hat[0, 2]\n",
    "    errVar_ETC[2] = Q_hat[2, 2] - (Q_hat[0, 2] * Q_hat[1, 2]) / Q_hat[0, 1]\n",
    "\n",
    "    # Check for negative error variances\n",
    "    if np.any(errVar_ETC < 0):\n",
    "        print('Warning: At least one calculated errVar is negative. This can happen if the sample size is too small or if one of the assumptions of ETC is violated.')\n",
    "\n",
    "    # Check for negative squared correlation coefficients\n",
    "    if np.any(rho2_ETC < 0):\n",
    "        print('Warning: At least one calculated squared correlation coefficient is negative. This can happen if the sample size is too small or if one of the assumptions of ETC is violated.')\n",
    "\n",
    "    # ======================================================\n",
    "    # Computer SNR\n",
    "    SNR = np.zeros(3)\n",
    "    SNRdb = np.zeros(3)\n",
    "\n",
    "    SNR[0] = (rho2_ETC[0]) / (1 - rho2_ETC[0])\n",
    "    SNRdb[0] = 10 * np.log10(SNR[0])\n",
    "    SNR[1] = (rho2_ETC[1]) / (1 - rho2_ETC[1])\n",
    "    SNRdb[1] = 10 * np.log10(SNR[1])\n",
    "    SNR[2] = (rho2_ETC[2]) / (1 - rho2_ETC[2])\n",
    "    SNRdb[2] = 10 * np.log10(SNR[2])\n",
    "\n",
    "    # Prepare outputs\n",
    "    VAR_err = {\n",
    "        'x': errVar_ETC[0],\n",
    "        'y': errVar_ETC[1],\n",
    "        'z': errVar_ETC[2]\n",
    "    }\n",
    "    SNR = {\n",
    "        'x': SNR[0],\n",
    "        'y': SNR[1],\n",
    "        'z': SNR[2]\n",
    "    }\n",
    "    SNRdb = {\n",
    "        'x': SNRdb[0],\n",
    "        'y': SNRdb[1],\n",
    "        'z': SNRdb[2]\n",
    "    }\n",
    "    R = {\n",
    "        'x': rho2_ETC[0],\n",
    "        'y': rho2_ETC[1],\n",
    "        'z': rho2_ETC[2]\n",
    "    }\n",
    "    fMSE = {\n",
    "        'x': 1 - rho2_ETC[0],\n",
    "        'y': 1 - rho2_ETC[1],\n",
    "        'z': 1 - rho2_ETC[2]\n",
    "    }\n",
    "    # Set the flags\n",
    "    # Flag on non-scaled data (not necessary here as we didn't calculate corrXY)\n",
    "    # flags on correlation coefficients\n",
    "    condition_corr = (R['x'] < corr_th) | (R['y'] < corr_th) | (R['z'] < corr_th)  # flag 1\n",
    "    # flag on valid number of observations\n",
    "    condition_n_valid = np.sum(~np.isnan(D1) & ~np.isnan(D2) & ~np.isnan(D3), axis=0) < nod_th # flag 2 (axis=0 is due to 1D array\n",
    "    # flags on fMSE\n",
    "    condition_fMSE = (fMSE['x'] < 0) | (fMSE['y'] < 0) | (fMSE['z'] < 0) | (fMSE['x'] > 1) | (fMSE['y'] > 1) | (fMSE['z'] > 1)  # flag 3\n",
    "    # flag on negative error variances\n",
    "    condition_negative_vars_err = (errVar_ETC < 0).any(axis=0)  # flag 4 (axis=0 is due to 1D array)\n",
    "\n",
    "    flags = {'condition_corr': condition_corr,\n",
    "            'condition_n_valid': condition_n_valid,\n",
    "            'condition_fMSE': condition_fMSE,\n",
    "            'condition_negative_vars_err': condition_negative_vars_err}\n",
    "\n",
    "    return VAR_err, SNR, SNRdb, R, fMSE, flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(0)  # For reproducibility\n",
    "\n",
    "N = 1000  # Number of data points\n",
    "\n",
    "# Generate the true signal T\n",
    "T = np.random.normal(0, 1, N)  # Mean 0, standard deviation 1\n",
    "\n",
    "# Generate errors for each dataset\n",
    "e1 = np.random.normal(0, 0.5, N)  # Error variance 0.25\n",
    "e2 = np.random.normal(0, 0.7, N)  # Error variance 0.49\n",
    "e3 = np.random.normal(0, 0.9, N)  # Error variance 0.81\n",
    "\n",
    "# Generate the datasets\n",
    "D1 = T + e1\n",
    "D2 = T + e2\n",
    "D3 = T + e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape data to 3D arrays with shape (1, 1, N)\n",
    "X = D1.reshape(1, 1, N)\n",
    "Y = D2.reshape(1, 1, N)\n",
    "Z = D3.reshape(1, 1, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(1, 1)\n",
      "[[0.23401675]]\n",
      "(1,)\n",
      "[0.23401675]\n",
      "()\n",
      "0.23401675296766955\n"
     ]
    }
   ],
   "source": [
    "# Previous TCA_vec_old code\n",
    "VAR_err_TCA_old, SNR_TCA_old, SNRdb_TCA_old, R_TCA_old, fMSE_TCA_old, flags_TCA_old = hTCL.TCA_vec_old(X, Y, Z)\n",
    "print(np.shape(VAR_err_TCA_old['x']))\n",
    "print(np.shape(flags_TCA_old['condition_n_valid']))\n",
    "print(VAR_err_TCA_old['x'])\n",
    "\n",
    "# Assume TCA_vec is already defined as per the modified code\n",
    "VAR_err_TCA, SNR_TCA, SNRdb_TCA, R_TCA, fMSE_TCA, flags_TCA = hTCL.TCA_vec(X, Y, Z)\n",
    "print(np.shape(VAR_err_TCA['x']))\n",
    "print(VAR_err_TCA['x'])\n",
    "\n",
    "# Assume ETC is already defined as per the provided code\n",
    "errVar_ETC, SNR_ETC, SNRdb_ETC, R_ETC, fMSE_ETC, flags_ETC = hTCL.ETC(D1, D2, D3)\n",
    "print(np.shape(errVar_ETC['x']))\n",
    "print(errVar_ETC['x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n",
      "(3,)\n",
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# Previous TCA_vec_old code\n",
    "errVar_TCA_old_x = VAR_err_TCA_old['x'][0, 0]  # Since the arrays have shape (1, 1)\n",
    "errVar_TCA_old_y = VAR_err_TCA_old['y'][0, 0]\n",
    "errVar_TCA_old_z = VAR_err_TCA_old['z'][0, 0]\n",
    "errVar_TCA_old = np.array([errVar_TCA_old_x, errVar_TCA_old_y, errVar_TCA_old_z])\n",
    "print(np.shape(errVar_TCA_old))\n",
    "\n",
    "# Extract error variances from TCA_vec outputs\n",
    "errVar_TCA_x = VAR_err_TCA['x'][0]  # Since the arrays have shape (1,)\n",
    "errVar_TCA_y = VAR_err_TCA['y'][0]\n",
    "errVar_TCA_z = VAR_err_TCA['z'][0]\n",
    "# Combine into a single array for comparison\n",
    "errVar_TCA = np.array([errVar_TCA_x, errVar_TCA_y, errVar_TCA_z])\n",
    "print(np.shape(errVar_TCA))\n",
    "\n",
    "# Extract error variances from ETC outputs\n",
    "errVar_ETC_x = errVar_ETC['x']\n",
    "errVar_ETC_y = errVar_ETC['y']\n",
    "errVar_ETC_z = errVar_ETC['z']\n",
    "# Combine into a single array for comparison\n",
    "errVar_ETC = np.array([errVar_ETC_x, errVar_ETC_y, errVar_ETC_z])\n",
    "print(np.shape(errVar_ETC))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Variances from TCA_vec_old:\n",
      "D1: 0.2340, D2: 0.4550, D3: 0.7692\n",
      "\n",
      "Error Variances from TCA_vec:\n",
      "D1: 0.2340, D2: 0.4474, D3: 0.8209\n",
      "\n",
      "Error Variances from ETC:\n",
      "D1: 0.2340, D2: 0.4474, D3: 0.8209\n"
     ]
    }
   ],
   "source": [
    "print(\"Error Variances from TCA_vec_old:\")\n",
    "print(f\"D1: {errVar_TCA_old[0]:.4f}, D2: {errVar_TCA_old[1]:.4f}, D3: {errVar_TCA_old[2]:.4f}\")\n",
    "\n",
    "print(\"\\nError Variances from TCA_vec:\")\n",
    "print(f\"D1: {errVar_TCA[0]:.4f}, D2: {errVar_TCA[1]:.4f}, D3: {errVar_TCA[2]:.4f}\")\n",
    "\n",
    "print(\"\\nError Variances from ETC:\")\n",
    "print(f\"D1: {errVar_ETC[0]:.4f}, D2: {errVar_ETC[1]:.4f}, D3: {errVar_ETC[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNR from TCA_vec_old:\n",
      "D1: 4.0408, D2: 2.0668, D3: 1.2247\n",
      "\n",
      "SNR from TCA_vec:\n",
      "D1: 4.0408, D2: 2.0668, D3: 1.2247\n",
      "\n",
      "SNR from ETC:\n",
      "D1: 4.0408, D2: 2.0668, D3: 1.2247\n"
     ]
    }
   ],
   "source": [
    "print(\"SNR from TCA_vec_old:\")\n",
    "print(f\"D1: {SNR_TCA_old['x'][0, 0]:.4f}, D2: {SNR_TCA_old['y'][0, 0]:.4f}, D3: {SNR_TCA_old['z'][0, 0]:.4f}\")\n",
    "\n",
    "print(\"\\nSNR from TCA_vec:\")\n",
    "print(f\"D1: {SNR_TCA['x'][0]:.4f}, D2: {SNR_TCA['y'][0]:.4f}, D3: {SNR_TCA['z'][0]:.4f}\")\n",
    "\n",
    "print(\"\\nSNR from ETC:\")\n",
    "print(f\"D1: {SNR_ETC['x']:.4f}, D2: {SNR_ETC['y']:.4f}, D3: {SNR_ETC['z']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNRdb from TCA_vec_old:\n",
      "D1: 6.0647, D2: 3.1530, D3: 0.8803\n",
      "\n",
      "SNRdb from TCA_vec:\n",
      "D1: 6.0647, D2: 3.1530, D3: 0.8803\n",
      "\n",
      "SNRdb from ETC:\n",
      "D1: 6.0647, D2: 3.1530, D3: 0.8803\n"
     ]
    }
   ],
   "source": [
    "print(\"SNRdb from TCA_vec_old:\")\n",
    "print(f\"D1: {SNRdb_TCA_old['x'][0, 0]:.4f}, D2: {SNRdb_TCA_old['y'][0, 0]:.4f}, D3: {SNRdb_TCA_old['z'][0, 0]:.4f}\")\n",
    "\n",
    "print(\"\\nSNRdb from TCA_vec:\")\n",
    "print(f\"D1: {SNRdb_TCA['x'][0]:.4f}, D2: {SNRdb_TCA['y'][0]:.4f}, D3: {SNRdb_TCA['z'][0]:.4f}\")\n",
    "\n",
    "print(\"\\nSNRdb from ETC:\")\n",
    "print(f\"D1: {SNRdb_ETC['x']:.4f}, D2: {SNRdb_ETC['y']:.4f}, D3: {SNRdb_ETC['z']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R from TCA_vec_old:\n",
      "D1: 0.8016, D2: 0.6739, D3: 0.5505\n",
      "\n",
      "R from TCA_vec:\n",
      "D1: 0.8016, D2: 0.6739, D3: 0.5505\n",
      "\n",
      "R from ETC:\n",
      "D1: 0.8016, D2: 0.6739, D3: 0.5505\n"
     ]
    }
   ],
   "source": [
    "print(\"R from TCA_vec_old:\")\n",
    "print(f\"D1: {R_TCA_old['x'][0, 0]:.4f}, D2: {R_TCA_old['y'][0, 0]:.4f}, D3: {R_TCA_old['z'][0, 0]:.4f}\")\n",
    "\n",
    "print(\"\\nR from TCA_vec:\")\n",
    "print(f\"D1: {R_TCA['x'][0]:.4f}, D2: {R_TCA['y'][0]:.4f}, D3: {R_TCA['z'][0]:.4f}\")\n",
    "\n",
    "print(\"\\nR from ETC:\")\n",
    "print(f\"D1: {R_ETC['x']:.4f}, D2: {R_ETC['y']:.4f}, D3: {R_ETC['z']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fMSE from TCA_vec_old:\n",
      "D1: 0.1984, D2: 0.3261, D3: 0.4495\n",
      "\n",
      "fMSE from TCA_vec:\n",
      "D1: 0.1984, D2: 0.3261, D3: 0.4495\n",
      "\n",
      "fMSE from ETC:\n",
      "D1: 0.1984, D2: 0.3261, D3: 0.4495\n"
     ]
    }
   ],
   "source": [
    "print(\"fMSE from TCA_vec_old:\")\n",
    "print(f\"D1: {fMSE_TCA_old['x'][0, 0]:.4f}, D2: {fMSE_TCA_old['y'][0, 0]:.4f}, D3: {fMSE_TCA_old['z'][0, 0]:.4f}\")\n",
    "\n",
    "print(\"\\nfMSE from TCA_vec:\")\n",
    "print(f\"D1: {fMSE_TCA['x'][0]:.4f}, D2: {fMSE_TCA['y'][0]:.4f}, D3: {fMSE_TCA['z'][0]:.4f}\")\n",
    "\n",
    "print(\"\\nfMSE from ETC:\")\n",
    "print(f\"D1: {fMSE_ETC['x']:.4f}, D2: {fMSE_ETC['y']:.4f}, D3: {fMSE_ETC['z']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flag1 from TCA_vec_old:\n",
      "D1: 0.0000, D2: 0.0000, D3: 0.0000\n",
      "\n",
      "flag1 from TCA_vec:\n",
      "D1: 0.0000, D2: 0.0000, D3: 0.0000\n",
      "\n",
      "flag1 from ETC:\n",
      "D1: 0.0000, D2: 0.0000, D3: 0.0000\n",
      "flag2 from TCA_vec_old:\n",
      "D1: 0.0000, D2: 0.0000, D3: 0.0000\n",
      "\n",
      "flag2 from TCA_vec:\n",
      "D1: 0.0000, D2: 0.0000, D3: 0.0000\n",
      "\n",
      "flag2 from ETC:\n",
      "D1: 0.0000, D2: 0.0000, D3: 0.0000\n",
      "flag3 from TCA_vec_old:\n",
      "D1: 0.0000, D2: 0.0000, D3: 0.0000\n",
      "\n",
      "flag3 from TCA_vec:\n",
      "D1: 0.0000, D2: 0.0000, D3: 0.0000\n",
      "\n",
      "flag3 from ETC:\n",
      "D1: 0.0000, D2: 0.0000, D3: 0.0000\n",
      "flag4 from TCA_vec_old:\n",
      "D1: 0.0000, D2: 0.0000, D3: 0.0000\n",
      "\n",
      "flag4 from TCA_vec:\n",
      "D1: 0.0000, D2: 0.0000, D3: 0.0000\n",
      "\n",
      "flag4 from ETC:\n",
      "D1: 0.0000, D2: 0.0000, D3: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print(\"flag1 from TCA_vec_old:\")\n",
    "print(f\"D1: {flags_TCA_old['condition_corr'][0, 0]:.4f}, D2: {flags_TCA_old['condition_corr'][0, 0]:.4f}, D3: {flags_TCA_old['condition_corr'][0, 0]:.4f}\")\n",
    "\n",
    "print(\"\\nflag1 from TCA_vec:\")\n",
    "print(f\"D1: {flags_TCA['condition_corr'][0]:.4f}, D2: {flags_TCA['condition_corr'][0]:.4f}, D3: {flags_TCA['condition_corr'][0]:.4f}\")\n",
    "\n",
    "print(\"\\nflag1 from ETC:\")\n",
    "print(f\"D1: {flags_ETC['condition_corr']:.4f}, D2: {flags_ETC['condition_corr']:.4f}, D3: {flags_ETC['condition_corr']:.4f}\")\n",
    "\n",
    "#======================================================\n",
    "print(\"flag2 from TCA_vec_old:\")\n",
    "print(f\"D1: {flags_TCA_old['condition_n_valid'][0, 0]:.4f}, D2: {flags_TCA_old['condition_n_valid'][0, 0]:.4f}, D3: {flags_TCA_old['condition_n_valid'][0, 0]:.4f}\")\n",
    "\n",
    "print(\"\\nflag2 from TCA_vec:\")\n",
    "print(f\"D1: {flags_TCA['condition_n_valid'][0]:.4f}, D2: {flags_TCA['condition_n_valid'][0]:.4f}, D3: {flags_TCA['condition_n_valid'][0]:.4f}\")\n",
    "\n",
    "print(\"\\nflag2 from ETC:\")\n",
    "print(f\"D1: {flags_ETC['condition_n_valid']:.4f}, D2: {flags_ETC['condition_n_valid']:.4f}, D3: {flags_ETC['condition_n_valid']:.4f}\")\n",
    "\n",
    "#======================================================\n",
    "print(\"flag3 from TCA_vec_old:\")\n",
    "print(f\"D1: {flags_TCA_old['condition_fMSE'][0, 0]:.4f}, D2: {flags_TCA_old['condition_fMSE'][0, 0]:.4f}, D3: {flags_TCA_old['condition_fMSE'][0, 0]:.4f}\")\n",
    "\n",
    "print(\"\\nflag3 from TCA_vec:\")\n",
    "print(f\"D1: {flags_TCA['condition_fMSE'][0]:.4f}, D2: {flags_TCA['condition_fMSE'][0]:.4f}, D3: {flags_TCA['condition_fMSE'][0]:.4f}\")\n",
    "\n",
    "print(\"\\nflag3 from ETC:\")\n",
    "print(f\"D1: {flags_ETC['condition_fMSE']:.4f}, D2: {flags_ETC['condition_fMSE']:.4f}, D3: {flags_ETC['condition_fMSE']:.4f}\")\n",
    "\n",
    "#======================================================\n",
    "print(\"flag4 from TCA_vec_old:\")\n",
    "print(f\"D1: {flags_TCA_old['condition_negative_vars_err'][0, 0]:.4f}, D2: {flags_TCA_old['condition_negative_vars_err'][0, 0]:.4f}, D3: {flags_TCA_old['condition_negative_vars_err'][0, 0]:.4f}\")\n",
    "\n",
    "print(\"\\nflag4 from TCA_vec:\")\n",
    "print(f\"D1: {flags_TCA['condition_negative_vars_err'][0]:.4f}, D2: {flags_TCA['condition_negative_vars_err'][0]:.4f}, D3: {flags_TCA['condition_negative_vars_err'][0]:.4f}\")\n",
    "\n",
    "print(\"\\nflag4 from ETC:\")\n",
    "print(f\"D1: {flags_ETC['condition_negative_vars_err']:.4f}, D2: {flags_ETC['condition_negative_vars_err']:.4f}, D3: {flags_ETC['condition_negative_vars_err']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 0.8016198649021953, 'y': 0.6739298406912139, 'z': 0.5505031959280736}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_ETC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': array([0.80161986]), 'y': array([0.67392984]), 'z': array([0.5505032])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R_TCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydroai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
